//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-34385749
// Cuda compilation tools, release 12.5, V12.5.82
// Based on NVVM 7.0.1
//

.version 8.5
.target sm_61
.address_size 64

	// .globl	is_i64_f16

.visible .entry is_i64_f16(
	.param .u64 is_i64_f16_param_0,
	.param .u64 is_i64_f16_param_1,
	.param .u64 is_i64_f16_param_2,
	.param .u64 is_i64_f16_param_3,
	.param .u64 is_i64_f16_param_4,
	.param .u64 is_i64_f16_param_5,
	.param .u64 is_i64_f16_param_6,
	.param .u64 is_i64_f16_param_7,
	.param .u64 is_i64_f16_param_8,
	.param .u64 is_i64_f16_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_i64_f16_param_0];
	ld.param.u64 	%rd51, [is_i64_f16_param_1];
	ld.param.u64 	%rd55, [is_i64_f16_param_2];
	ld.param.u64 	%rd56, [is_i64_f16_param_3];
	ld.param.u64 	%rd57, [is_i64_f16_param_4];
	ld.param.u64 	%rd58, [is_i64_f16_param_5];
	ld.param.u64 	%rd52, [is_i64_f16_param_7];
	ld.param.u64 	%rd53, [is_i64_f16_param_8];
	ld.param.u64 	%rd54, [is_i64_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB0_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB0_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB0_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB0_5;

$L__BB0_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB0_2;

$L__BB0_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB0_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB0_17;

$L__BB0_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB0_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB0_10;

$L__BB0_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB0_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB0_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB0_13;

$L__BB0_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB0_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB0_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB0_16;

$L__BB0_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB0_16:
	shl.b64 	%rd73, %rd116, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 1;
	and.b64  	%rd81, %rd80, 8589934590;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u16 	%rs5, [%rd82];
	shl.b64 	%rd83, %rd112, 1;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u16 	[%rd84], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB0_7;
	bra.uni 	$L__BB0_33;

$L__BB0_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB0_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB0_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB0_21;

$L__BB0_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB0_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB0_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB0_24;

$L__BB0_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB0_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB0_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB0_27;

$L__BB0_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB0_27:
	shl.b64 	%rd90, %rd121, 3;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u64 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd92, %rd93;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB0_32;

$L__BB0_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB0_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB0_31;

$L__BB0_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB0_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB0_28;

$L__BB0_32:
	mul.wide.u32 	%rd107, %r56, 2;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u16 	%rs6, [%rd108];
	shl.b64 	%rd109, %rd112, 1;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.u16 	[%rd110], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB0_18;

$L__BB0_33:
	ret;

}
	// .globl	is_u32_f16
.visible .entry is_u32_f16(
	.param .u64 is_u32_f16_param_0,
	.param .u64 is_u32_f16_param_1,
	.param .u64 is_u32_f16_param_2,
	.param .u64 is_u32_f16_param_3,
	.param .u64 is_u32_f16_param_4,
	.param .u64 is_u32_f16_param_5,
	.param .u64 is_u32_f16_param_6,
	.param .u64 is_u32_f16_param_7,
	.param .u64 is_u32_f16_param_8,
	.param .u64 is_u32_f16_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_u32_f16_param_0];
	ld.param.u64 	%rd51, [is_u32_f16_param_1];
	ld.param.u64 	%rd55, [is_u32_f16_param_2];
	ld.param.u64 	%rd56, [is_u32_f16_param_3];
	ld.param.u64 	%rd57, [is_u32_f16_param_4];
	ld.param.u64 	%rd58, [is_u32_f16_param_5];
	ld.param.u64 	%rd52, [is_u32_f16_param_7];
	ld.param.u64 	%rd53, [is_u32_f16_param_8];
	ld.param.u64 	%rd54, [is_u32_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB1_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB1_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB1_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB1_5;

$L__BB1_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB1_2;

$L__BB1_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB1_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB1_17;

$L__BB1_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB1_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB1_10;

$L__BB1_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB1_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB1_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB1_13;

$L__BB1_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB1_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB1_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB1_16;

$L__BB1_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB1_16:
	shl.b64 	%rd73, %rd116, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 1;
	and.b64  	%rd81, %rd80, 8589934590;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u16 	%rs5, [%rd82];
	shl.b64 	%rd83, %rd112, 1;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u16 	[%rd84], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB1_7;
	bra.uni 	$L__BB1_33;

$L__BB1_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB1_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB1_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB1_21;

$L__BB1_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB1_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB1_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB1_24;

$L__BB1_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB1_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB1_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB1_27;

$L__BB1_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB1_27:
	shl.b64 	%rd90, %rd121, 2;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u32 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd93, %rd92;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB1_32;

$L__BB1_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB1_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB1_31;

$L__BB1_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB1_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB1_28;

$L__BB1_32:
	mul.wide.u32 	%rd107, %r56, 2;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u16 	%rs6, [%rd108];
	shl.b64 	%rd109, %rd112, 1;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.u16 	[%rd110], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB1_18;

$L__BB1_33:
	ret;

}
	// .globl	is_u8_f16
.visible .entry is_u8_f16(
	.param .u64 is_u8_f16_param_0,
	.param .u64 is_u8_f16_param_1,
	.param .u64 is_u8_f16_param_2,
	.param .u64 is_u8_f16_param_3,
	.param .u64 is_u8_f16_param_4,
	.param .u64 is_u8_f16_param_5,
	.param .u64 is_u8_f16_param_6,
	.param .u64 is_u8_f16_param_7,
	.param .u64 is_u8_f16_param_8,
	.param .u64 is_u8_f16_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd50, [is_u8_f16_param_0];
	ld.param.u64 	%rd51, [is_u8_f16_param_1];
	ld.param.u64 	%rd55, [is_u8_f16_param_2];
	ld.param.u64 	%rd56, [is_u8_f16_param_3];
	ld.param.u64 	%rd57, [is_u8_f16_param_4];
	ld.param.u64 	%rd58, [is_u8_f16_param_5];
	ld.param.u64 	%rd52, [is_u8_f16_param_7];
	ld.param.u64 	%rd53, [is_u8_f16_param_8];
	ld.param.u64 	%rd54, [is_u8_f16_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB2_5;

	mov.u64 	%rd109, 1;
	mov.u32 	%r52, 0;

$L__BB2_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB2_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd109, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB2_5;

$L__BB2_4:
	mul.lo.s64 	%rd109, %rd7, %rd109;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB2_2;

$L__BB2_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r53;
	setp.ge.u64 	%p5, %rd110, %rd50;
	@%p5 bra 	$L__BB2_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB2_17;

$L__BB2_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB2_9;

	div.u64 	%rd111, %rd110, %rd10;
	bra.uni 	$L__BB2_10;

$L__BB2_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB2_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB2_12;

	div.u64 	%rd112, %rd110, %rd54;
	mul.lo.s64 	%rd70, %rd112, %rd54;
	sub.s64 	%rd113, %rd110, %rd70;
	bra.uni 	$L__BB2_13;

$L__BB2_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB2_13:
	or.b64  	%rd71, %rd112, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB2_15;

	rem.u64 	%rd114, %rd112, %rd53;
	bra.uni 	$L__BB2_16;

$L__BB2_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB2_16:
	add.s64 	%rd73, %rd3, %rd114;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd111, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd113;
	shl.b64 	%rd79, %rd78, 1;
	and.b64  	%rd80, %rd79, 8589934590;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u16 	%rs5, [%rd81];
	shl.b64 	%rd82, %rd110, 1;
	add.s64 	%rd83, %rd1, %rd82;
	st.global.u16 	[%rd83], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p10, %rd110, %rd50;
	@%p10 bra 	$L__BB2_7;
	bra.uni 	$L__BB2_33;

$L__BB2_17:
	and.b64  	%rd84, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB2_18:
	setp.eq.s64 	%p11, %rd84, 0;
	@%p11 bra 	$L__BB2_20;

	div.u64 	%rd116, %rd110, %rd10;
	bra.uni 	$L__BB2_21;

$L__BB2_20:
	cvt.u32.u64 	%r32, %rd110;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd116, %r33;

$L__BB2_21:
	and.b64  	%rd85, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd85, 0;
	@%p12 bra 	$L__BB2_23;

	div.u64 	%rd117, %rd110, %rd54;
	mul.lo.s64 	%rd86, %rd117, %rd54;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB2_24;

$L__BB2_23:
	cvt.u32.u64 	%r35, %rd110;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd117, %r36;
	cvt.u64.u32 	%rd118, %r38;

$L__BB2_24:
	or.b64  	%rd87, %rd117, %rd53;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p13, %rd88, 0;
	@%p13 bra 	$L__BB2_26;

	rem.u64 	%rd119, %rd117, %rd53;
	bra.uni 	$L__BB2_27;

$L__BB2_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd117;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd119, %r41;

$L__BB2_27:
	add.s64 	%rd89, %rd3, %rd119;
	ld.global.u8 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd116, %rd52;
	add.s64 	%rd92, %rd91, %rd90;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd120, %rd93, %rd118;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB2_32;

$L__BB2_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd94, %r45;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd120, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB2_30;

	div.u64 	%rd120, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd120, %rd42;
	sub.s64 	%rd122, %rd40, %rd99;
	bra.uni 	$L__BB2_31;

$L__BB2_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd120, %r48;
	cvt.u64.u32 	%rd122, %r50;

$L__BB2_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd122;
	cvt.u32.u64 	%r51, %rd103;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd104, %r55;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB2_28;

$L__BB2_32:
	mul.wide.u32 	%rd105, %r56, 2;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.u16 	%rs6, [%rd106];
	shl.b64 	%rd107, %rd110, 1;
	add.s64 	%rd108, %rd1, %rd107;
	st.global.u16 	[%rd108], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p17, %rd110, %rd50;
	@%p17 bra 	$L__BB2_18;

$L__BB2_33:
	ret;

}
	// .globl	gather_i64_f16
.visible .entry gather_i64_f16(
	.param .u64 gather_i64_f16_param_0,
	.param .u64 gather_i64_f16_param_1,
	.param .u64 gather_i64_f16_param_2,
	.param .u64 gather_i64_f16_param_3,
	.param .u64 gather_i64_f16_param_4,
	.param .u64 gather_i64_f16_param_5,
	.param .u64 gather_i64_f16_param_6,
	.param .u64 gather_i64_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f16_param_0];
	ld.param.u64 	%rd16, [gather_i64_f16_param_1];
	ld.param.u64 	%rd17, [gather_i64_f16_param_2];
	ld.param.u64 	%rd18, [gather_i64_f16_param_3];
	ld.param.u64 	%rd19, [gather_i64_f16_param_5];
	ld.param.u64 	%rd20, [gather_i64_f16_param_6];
	ld.param.u64 	%rd21, [gather_i64_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB3_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB3_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB3_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB3_5;

$L__BB3_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB3_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB3_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB3_8;

$L__BB3_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB3_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs1, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB3_2;

$L__BB3_9:
	ret;

}
	// .globl	gather_u32_f16
.visible .entry gather_u32_f16(
	.param .u64 gather_u32_f16_param_0,
	.param .u64 gather_u32_f16_param_1,
	.param .u64 gather_u32_f16_param_2,
	.param .u64 gather_u32_f16_param_3,
	.param .u64 gather_u32_f16_param_4,
	.param .u64 gather_u32_f16_param_5,
	.param .u64 gather_u32_f16_param_6,
	.param .u64 gather_u32_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f16_param_0];
	ld.param.u64 	%rd15, [gather_u32_f16_param_1];
	ld.param.u64 	%rd16, [gather_u32_f16_param_2];
	ld.param.u64 	%rd17, [gather_u32_f16_param_3];
	ld.param.u64 	%rd18, [gather_u32_f16_param_5];
	ld.param.u64 	%rd19, [gather_u32_f16_param_6];
	ld.param.u64 	%rd20, [gather_u32_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB4_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB4_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB4_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB4_5;

$L__BB4_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB4_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB4_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB4_8;

$L__BB4_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB4_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs1, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB4_2;

$L__BB4_9:
	ret;

}
	// .globl	gather_u8_f16
.visible .entry gather_u8_f16(
	.param .u64 gather_u8_f16_param_0,
	.param .u64 gather_u8_f16_param_1,
	.param .u64 gather_u8_f16_param_2,
	.param .u64 gather_u8_f16_param_3,
	.param .u64 gather_u8_f16_param_4,
	.param .u64 gather_u8_f16_param_5,
	.param .u64 gather_u8_f16_param_6,
	.param .u64 gather_u8_f16_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f16_param_0];
	ld.param.u64 	%rd15, [gather_u8_f16_param_1];
	ld.param.u64 	%rd16, [gather_u8_f16_param_2];
	ld.param.u64 	%rd17, [gather_u8_f16_param_3];
	ld.param.u64 	%rd18, [gather_u8_f16_param_5];
	ld.param.u64 	%rd19, [gather_u8_f16_param_6];
	ld.param.u64 	%rd20, [gather_u8_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB5_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB5_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB5_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB5_5;

$L__BB5_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB5_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB5_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB5_8;

$L__BB5_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB5_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 1;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u16 	%rs2, [%rd31];
	shl.b64 	%rd32, %rd34, 1;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u16 	[%rd33], %rs2;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB5_2;

$L__BB5_9:
	ret;

}
	// .globl	ia_i64_f16
.visible .entry ia_i64_f16(
	.param .u64 ia_i64_f16_param_0,
	.param .u64 ia_i64_f16_param_1,
	.param .u64 ia_i64_f16_param_2,
	.param .u64 ia_i64_f16_param_3,
	.param .u64 ia_i64_f16_param_4,
	.param .u64 ia_i64_f16_param_5,
	.param .u64 ia_i64_f16_param_6,
	.param .u64 ia_i64_f16_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_f16_param_0];
	ld.param.u64 	%rd19, [ia_i64_f16_param_1];
	ld.param.u64 	%rd20, [ia_i64_f16_param_2];
	ld.param.u64 	%rd21, [ia_i64_f16_param_3];
	ld.param.u64 	%rd24, [ia_i64_f16_param_4];
	ld.param.u64 	%rd22, [ia_i64_f16_param_6];
	ld.param.u64 	%rd23, [ia_i64_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB6_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB6_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB6_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB6_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB6_6;

$L__BB6_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB6_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB6_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd30, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB6_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB6_3;
	bra.uni 	$L__BB6_10;

$L__BB6_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB6_9;

$L__BB6_10:
	ret;

}
	// .globl	ia_u32_f16
.visible .entry ia_u32_f16(
	.param .u64 ia_u32_f16_param_0,
	.param .u64 ia_u32_f16_param_1,
	.param .u64 ia_u32_f16_param_2,
	.param .u64 ia_u32_f16_param_3,
	.param .u64 ia_u32_f16_param_4,
	.param .u64 ia_u32_f16_param_5,
	.param .u64 ia_u32_f16_param_6,
	.param .u64 ia_u32_f16_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f16_param_0];
	ld.param.u64 	%rd19, [ia_u32_f16_param_1];
	ld.param.u64 	%rd20, [ia_u32_f16_param_2];
	ld.param.u64 	%rd21, [ia_u32_f16_param_3];
	ld.param.u64 	%rd24, [ia_u32_f16_param_4];
	ld.param.u64 	%rd22, [ia_u32_f16_param_6];
	ld.param.u64 	%rd23, [ia_u32_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB7_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB7_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB7_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB7_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB7_6;

$L__BB7_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB7_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB7_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd33, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB7_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB7_3;
	bra.uni 	$L__BB7_10;

$L__BB7_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB7_9;

$L__BB7_10:
	ret;

}
	// .globl	ia_u8_f16
.visible .entry ia_u8_f16(
	.param .u64 ia_u8_f16_param_0,
	.param .u64 ia_u8_f16_param_1,
	.param .u64 ia_u8_f16_param_2,
	.param .u64 ia_u8_f16_param_3,
	.param .u64 ia_u8_f16_param_4,
	.param .u64 ia_u8_f16_param_5,
	.param .u64 ia_u8_f16_param_6,
	.param .u64 ia_u8_f16_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f16_param_0];
	ld.param.u64 	%rd19, [ia_u8_f16_param_1];
	ld.param.u64 	%rd20, [ia_u8_f16_param_2];
	ld.param.u64 	%rd21, [ia_u8_f16_param_3];
	ld.param.u64 	%rd24, [ia_u8_f16_param_4];
	ld.param.u64 	%rd22, [ia_u8_f16_param_6];
	ld.param.u64 	%rd23, [ia_u8_f16_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB8_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB8_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd21;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB8_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB8_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB8_6;

$L__BB8_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB8_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB8_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd35, 1;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u16 	%rs2, [%rd37];
	shl.b64 	%rd38, %rd32, 1;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u16 	%rs3, [%rd39];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd37], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB8_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB8_3;
	bra.uni 	$L__BB8_10;

$L__BB8_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB8_9;

$L__BB8_10:
	ret;

}
	// .globl	sa_i64_f16
.visible .entry sa_i64_f16(
	.param .u64 sa_i64_f16_param_0,
	.param .u64 sa_i64_f16_param_1,
	.param .u64 sa_i64_f16_param_2,
	.param .u64 sa_i64_f16_param_3,
	.param .u64 sa_i64_f16_param_4,
	.param .u64 sa_i64_f16_param_5,
	.param .u64 sa_i64_f16_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_i64_f16_param_0];
	ld.param.u64 	%rd19, [sa_i64_f16_param_1];
	ld.param.u64 	%rd20, [sa_i64_f16_param_2];
	ld.param.u64 	%rd24, [sa_i64_f16_param_3];
	ld.param.u64 	%rd21, [sa_i64_f16_param_4];
	ld.param.u64 	%rd22, [sa_i64_f16_param_5];
	ld.param.u64 	%rd23, [sa_i64_f16_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB9_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB9_9;

	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB9_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB9_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB9_6;

$L__BB9_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB9_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB9_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd30, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB9_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB9_3;
	bra.uni 	$L__BB9_10;

$L__BB9_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB9_9;

$L__BB9_10:
	ret;

}
	// .globl	sa_u32_f16
.visible .entry sa_u32_f16(
	.param .u64 sa_u32_f16_param_0,
	.param .u64 sa_u32_f16_param_1,
	.param .u64 sa_u32_f16_param_2,
	.param .u64 sa_u32_f16_param_3,
	.param .u64 sa_u32_f16_param_4,
	.param .u64 sa_u32_f16_param_5,
	.param .u64 sa_u32_f16_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_u32_f16_param_0];
	ld.param.u64 	%rd19, [sa_u32_f16_param_1];
	ld.param.u64 	%rd20, [sa_u32_f16_param_2];
	ld.param.u64 	%rd24, [sa_u32_f16_param_3];
	ld.param.u64 	%rd21, [sa_u32_f16_param_4];
	ld.param.u64 	%rd22, [sa_u32_f16_param_5];
	ld.param.u64 	%rd23, [sa_u32_f16_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB10_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB10_9;

	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB10_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB10_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB10_6;

$L__BB10_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB10_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB10_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd36, 1;
	add.s64 	%rd38, %rd4, %rd37;
	ld.global.u16 	%rs2, [%rd38];
	shl.b64 	%rd39, %rd30, 1;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u16 	%rs3, [%rd40];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd38], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB10_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB10_3;
	bra.uni 	$L__BB10_10;

$L__BB10_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB10_9;

$L__BB10_10:
	ret;

}
	// .globl	sa_u8_f16
.visible .entry sa_u8_f16(
	.param .u64 sa_u8_f16_param_0,
	.param .u64 sa_u8_f16_param_1,
	.param .u64 sa_u8_f16_param_2,
	.param .u64 sa_u8_f16_param_3,
	.param .u64 sa_u8_f16_param_4,
	.param .u64 sa_u8_f16_param_5,
	.param .u64 sa_u8_f16_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f16_param_0];
	ld.param.u64 	%rd19, [sa_u8_f16_param_1];
	ld.param.u64 	%rd20, [sa_u8_f16_param_2];
	ld.param.u64 	%rd24, [sa_u8_f16_param_3];
	ld.param.u64 	%rd21, [sa_u8_f16_param_4];
	ld.param.u64 	%rd22, [sa_u8_f16_param_5];
	ld.param.u64 	%rd23, [sa_u8_f16_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB11_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB11_9;

	cvta.to.global.u64 	%rd3, %rd19;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB11_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB11_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB11_6;

$L__BB11_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB11_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB11_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd35, 1;
	add.s64 	%rd37, %rd4, %rd36;
	ld.global.u16 	%rs2, [%rd37];
	shl.b64 	%rd38, %rd30, 1;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u16 	%rs3, [%rd39];
	// begin inline asm
	{add.f16 %rs1,%rs2,%rs3;
}
	// end inline asm
	st.global.u16 	[%rd37], %rs1;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB11_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB11_3;
	bra.uni 	$L__BB11_10;

$L__BB11_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB11_9;

$L__BB11_10:
	ret;

}
	// .globl	is_i64_f32
.visible .entry is_i64_f32(
	.param .u64 is_i64_f32_param_0,
	.param .u64 is_i64_f32_param_1,
	.param .u64 is_i64_f32_param_2,
	.param .u64 is_i64_f32_param_3,
	.param .u64 is_i64_f32_param_4,
	.param .u64 is_i64_f32_param_5,
	.param .u64 is_i64_f32_param_6,
	.param .u64 is_i64_f32_param_7,
	.param .u64 is_i64_f32_param_8,
	.param .u64 is_i64_f32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_i64_f32_param_0];
	ld.param.u64 	%rd51, [is_i64_f32_param_1];
	ld.param.u64 	%rd55, [is_i64_f32_param_2];
	ld.param.u64 	%rd56, [is_i64_f32_param_3];
	ld.param.u64 	%rd57, [is_i64_f32_param_4];
	ld.param.u64 	%rd58, [is_i64_f32_param_5];
	ld.param.u64 	%rd52, [is_i64_f32_param_7];
	ld.param.u64 	%rd53, [is_i64_f32_param_8];
	ld.param.u64 	%rd54, [is_i64_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB12_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB12_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB12_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB12_5;

$L__BB12_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB12_2;

$L__BB12_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB12_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB12_17;

$L__BB12_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB12_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB12_10;

$L__BB12_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB12_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB12_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB12_13;

$L__BB12_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB12_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB12_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB12_16;

$L__BB12_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB12_16:
	shl.b64 	%rd73, %rd116, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f32 	%f1, [%rd82];
	shl.b64 	%rd83, %rd112, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f32 	[%rd84], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB12_7;
	bra.uni 	$L__BB12_33;

$L__BB12_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB12_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB12_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB12_21;

$L__BB12_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB12_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB12_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB12_24;

$L__BB12_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB12_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB12_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB12_27;

$L__BB12_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB12_27:
	shl.b64 	%rd90, %rd121, 3;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u64 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd92, %rd93;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB12_32;

$L__BB12_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB12_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB12_31;

$L__BB12_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB12_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB12_28;

$L__BB12_32:
	mul.wide.u32 	%rd107, %r56, 4;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.f32 	%f2, [%rd108];
	shl.b64 	%rd109, %rd112, 2;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.f32 	[%rd110], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB12_18;

$L__BB12_33:
	ret;

}
	// .globl	is_i64_f64
.visible .entry is_i64_f64(
	.param .u64 is_i64_f64_param_0,
	.param .u64 is_i64_f64_param_1,
	.param .u64 is_i64_f64_param_2,
	.param .u64 is_i64_f64_param_3,
	.param .u64 is_i64_f64_param_4,
	.param .u64 is_i64_f64_param_5,
	.param .u64 is_i64_f64_param_6,
	.param .u64 is_i64_f64_param_7,
	.param .u64 is_i64_f64_param_8,
	.param .u64 is_i64_f64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_i64_f64_param_0];
	ld.param.u64 	%rd51, [is_i64_f64_param_1];
	ld.param.u64 	%rd55, [is_i64_f64_param_2];
	ld.param.u64 	%rd56, [is_i64_f64_param_3];
	ld.param.u64 	%rd57, [is_i64_f64_param_4];
	ld.param.u64 	%rd58, [is_i64_f64_param_5];
	ld.param.u64 	%rd52, [is_i64_f64_param_7];
	ld.param.u64 	%rd53, [is_i64_f64_param_8];
	ld.param.u64 	%rd54, [is_i64_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB13_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB13_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB13_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB13_5;

$L__BB13_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB13_2;

$L__BB13_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB13_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB13_17;

$L__BB13_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB13_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB13_10;

$L__BB13_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB13_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB13_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB13_13;

$L__BB13_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB13_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB13_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB13_16;

$L__BB13_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB13_16:
	shl.b64 	%rd73, %rd116, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f64 	%fd1, [%rd82];
	shl.b64 	%rd83, %rd112, 3;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f64 	[%rd84], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB13_7;
	bra.uni 	$L__BB13_33;

$L__BB13_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB13_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB13_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB13_21;

$L__BB13_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB13_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB13_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB13_24;

$L__BB13_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB13_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB13_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB13_27;

$L__BB13_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB13_27:
	shl.b64 	%rd90, %rd121, 3;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u64 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd92, %rd93;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB13_32;

$L__BB13_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB13_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB13_31;

$L__BB13_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB13_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB13_28;

$L__BB13_32:
	mul.wide.u32 	%rd107, %r56, 8;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.f64 	%fd2, [%rd108];
	shl.b64 	%rd109, %rd112, 3;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.f64 	[%rd110], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB13_18;

$L__BB13_33:
	ret;

}
	// .globl	is_i64_u8
.visible .entry is_i64_u8(
	.param .u64 is_i64_u8_param_0,
	.param .u64 is_i64_u8_param_1,
	.param .u64 is_i64_u8_param_2,
	.param .u64 is_i64_u8_param_3,
	.param .u64 is_i64_u8_param_4,
	.param .u64 is_i64_u8_param_5,
	.param .u64 is_i64_u8_param_6,
	.param .u64 is_i64_u8_param_7,
	.param .u64 is_i64_u8_param_8,
	.param .u64 is_i64_u8_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<122>;


	ld.param.u64 	%rd50, [is_i64_u8_param_0];
	ld.param.u64 	%rd51, [is_i64_u8_param_1];
	ld.param.u64 	%rd55, [is_i64_u8_param_2];
	ld.param.u64 	%rd56, [is_i64_u8_param_3];
	ld.param.u64 	%rd57, [is_i64_u8_param_4];
	ld.param.u64 	%rd58, [is_i64_u8_param_5];
	ld.param.u64 	%rd52, [is_i64_u8_param_7];
	ld.param.u64 	%rd53, [is_i64_u8_param_8];
	ld.param.u64 	%rd54, [is_i64_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB14_5;

	mov.u64 	%rd108, 1;
	mov.u32 	%r52, 0;

$L__BB14_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB14_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd108, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB14_5;

$L__BB14_4:
	mul.lo.s64 	%rd108, %rd7, %rd108;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB14_2;

$L__BB14_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd109, %r53;
	setp.ge.u64 	%p5, %rd109, %rd50;
	@%p5 bra 	$L__BB14_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB14_17;

$L__BB14_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB14_9;

	div.u64 	%rd110, %rd109, %rd10;
	bra.uni 	$L__BB14_10;

$L__BB14_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd109;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd110, %r22;

$L__BB14_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB14_12;

	div.u64 	%rd111, %rd109, %rd54;
	mul.lo.s64 	%rd70, %rd111, %rd54;
	sub.s64 	%rd112, %rd109, %rd70;
	bra.uni 	$L__BB14_13;

$L__BB14_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd109;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd111, %r25;
	cvt.u64.u32 	%rd112, %r27;

$L__BB14_13:
	or.b64  	%rd71, %rd111, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB14_15;

	rem.u64 	%rd113, %rd111, %rd53;
	bra.uni 	$L__BB14_16;

$L__BB14_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd111;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd113, %r30;

$L__BB14_16:
	shl.b64 	%rd73, %rd113, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd110, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd112;
	and.b64  	%rd80, %rd79, 4294967295;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u8 	%rs5, [%rd81];
	add.s64 	%rd82, %rd1, %rd109;
	st.global.u8 	[%rd82], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd109, %r53;
	setp.lt.u64 	%p10, %rd109, %rd50;
	@%p10 bra 	$L__BB14_7;
	bra.uni 	$L__BB14_33;

$L__BB14_17:
	and.b64  	%rd83, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB14_18:
	setp.eq.s64 	%p11, %rd83, 0;
	@%p11 bra 	$L__BB14_20;

	div.u64 	%rd115, %rd109, %rd10;
	bra.uni 	$L__BB14_21;

$L__BB14_20:
	cvt.u32.u64 	%r32, %rd109;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd115, %r33;

$L__BB14_21:
	and.b64  	%rd84, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd84, 0;
	@%p12 bra 	$L__BB14_23;

	div.u64 	%rd116, %rd109, %rd54;
	mul.lo.s64 	%rd85, %rd116, %rd54;
	sub.s64 	%rd117, %rd109, %rd85;
	bra.uni 	$L__BB14_24;

$L__BB14_23:
	cvt.u32.u64 	%r35, %rd109;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd116, %r36;
	cvt.u64.u32 	%rd117, %r38;

$L__BB14_24:
	or.b64  	%rd86, %rd116, %rd53;
	and.b64  	%rd87, %rd86, -4294967296;
	setp.eq.s64 	%p13, %rd87, 0;
	@%p13 bra 	$L__BB14_26;

	rem.u64 	%rd118, %rd116, %rd53;
	bra.uni 	$L__BB14_27;

$L__BB14_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd116;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd118, %r41;

$L__BB14_27:
	shl.b64 	%rd88, %rd118, 3;
	add.s64 	%rd89, %rd3, %rd88;
	ld.global.u64 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd115, %rd52;
	add.s64 	%rd92, %rd90, %rd91;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd119, %rd93, %rd117;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB14_32;

$L__BB14_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd94, %r45;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd119, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB14_30;

	div.u64 	%rd119, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd119, %rd42;
	sub.s64 	%rd121, %rd40, %rd99;
	bra.uni 	$L__BB14_31;

$L__BB14_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd119, %r48;
	cvt.u64.u32 	%rd121, %r50;

$L__BB14_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd121;
	cvt.u32.u64 	%r51, %rd103;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd104, %r55;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB14_28;

$L__BB14_32:
	cvt.u64.u32 	%rd105, %r56;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.u8 	%rs6, [%rd106];
	add.s64 	%rd107, %rd1, %rd109;
	st.global.u8 	[%rd107], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd109, %r53;
	setp.lt.u64 	%p17, %rd109, %rd50;
	@%p17 bra 	$L__BB14_18;

$L__BB14_33:
	ret;

}
	// .globl	is_i64_u32
.visible .entry is_i64_u32(
	.param .u64 is_i64_u32_param_0,
	.param .u64 is_i64_u32_param_1,
	.param .u64 is_i64_u32_param_2,
	.param .u64 is_i64_u32_param_3,
	.param .u64 is_i64_u32_param_4,
	.param .u64 is_i64_u32_param_5,
	.param .u64 is_i64_u32_param_6,
	.param .u64 is_i64_u32_param_7,
	.param .u64 is_i64_u32_param_8,
	.param .u64 is_i64_u32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_i64_u32_param_0];
	ld.param.u64 	%rd51, [is_i64_u32_param_1];
	ld.param.u64 	%rd55, [is_i64_u32_param_2];
	ld.param.u64 	%rd56, [is_i64_u32_param_3];
	ld.param.u64 	%rd57, [is_i64_u32_param_4];
	ld.param.u64 	%rd58, [is_i64_u32_param_5];
	ld.param.u64 	%rd52, [is_i64_u32_param_7];
	ld.param.u64 	%rd53, [is_i64_u32_param_8];
	ld.param.u64 	%rd54, [is_i64_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB15_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r54, 0;

$L__BB15_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB15_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB15_5;

$L__BB15_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd67, %r54;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB15_2;

$L__BB15_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r55;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB15_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB15_17;

$L__BB15_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB15_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB15_10;

$L__BB15_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB15_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB15_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB15_13;

$L__BB15_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB15_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB15_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB15_16;

$L__BB15_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB15_16:
	shl.b64 	%rd73, %rd116, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u32 	%r31, [%rd82];
	shl.b64 	%rd83, %rd112, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u32 	[%rd84], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd112, %r55;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB15_7;
	bra.uni 	$L__BB15_33;

$L__BB15_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd54;

$L__BB15_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB15_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB15_21;

$L__BB15_20:
	cvt.u32.u64 	%r33, %rd112;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd118, %r34;

$L__BB15_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB15_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB15_24;

$L__BB15_23:
	cvt.u32.u64 	%r36, %rd112;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd119, %r37;
	cvt.u64.u32 	%rd120, %r39;

$L__BB15_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB15_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB15_27;

$L__BB15_26:
	cvt.u32.u64 	%r40, %rd53;
	cvt.u32.u64 	%r41, %rd119;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd121, %r42;

$L__BB15_27:
	shl.b64 	%rd90, %rd121, 3;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u64 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd92, %rd93;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB15_32;

$L__BB15_28:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd96, %r46;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB15_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB15_31;

$L__BB15_30:
	cvt.u32.u64 	%r47, %rd42;
	cvt.u32.u64 	%r48, %rd40;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd122, %r49;
	cvt.u64.u32 	%rd124, %r51;

$L__BB15_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r52, %rd105;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd106, %r57;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB15_28;

$L__BB15_32:
	mul.wide.u32 	%rd107, %r58, 4;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u32 	%r53, [%rd108];
	shl.b64 	%rd109, %rd112, 2;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.u32 	[%rd110], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd112, %r55;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB15_18;

$L__BB15_33:
	ret;

}
	// .globl	is_i64_i64
.visible .entry is_i64_i64(
	.param .u64 is_i64_i64_param_0,
	.param .u64 is_i64_i64_param_1,
	.param .u64 is_i64_i64_param_2,
	.param .u64 is_i64_i64_param_3,
	.param .u64 is_i64_i64_param_4,
	.param .u64 is_i64_i64_param_5,
	.param .u64 is_i64_i64_param_6,
	.param .u64 is_i64_i64_param_7,
	.param .u64 is_i64_i64_param_8,
	.param .u64 is_i64_i64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<127>;


	ld.param.u64 	%rd50, [is_i64_i64_param_0];
	ld.param.u64 	%rd51, [is_i64_i64_param_1];
	ld.param.u64 	%rd55, [is_i64_i64_param_2];
	ld.param.u64 	%rd56, [is_i64_i64_param_3];
	ld.param.u64 	%rd57, [is_i64_i64_param_4];
	ld.param.u64 	%rd58, [is_i64_i64_param_5];
	ld.param.u64 	%rd52, [is_i64_i64_param_7];
	ld.param.u64 	%rd53, [is_i64_i64_param_8];
	ld.param.u64 	%rd54, [is_i64_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB16_5;

	mov.u64 	%rd113, 1;
	mov.u32 	%r52, 0;

$L__BB16_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB16_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd113, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB16_5;

$L__BB16_4:
	mul.lo.s64 	%rd113, %rd7, %rd113;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB16_2;

$L__BB16_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd114, %r53;
	setp.ge.u64 	%p5, %rd114, %rd50;
	@%p5 bra 	$L__BB16_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB16_17;

$L__BB16_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB16_9;

	div.u64 	%rd115, %rd114, %rd10;
	bra.uni 	$L__BB16_10;

$L__BB16_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd114;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd115, %r22;

$L__BB16_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB16_12;

	div.u64 	%rd116, %rd114, %rd54;
	mul.lo.s64 	%rd70, %rd116, %rd54;
	sub.s64 	%rd117, %rd114, %rd70;
	bra.uni 	$L__BB16_13;

$L__BB16_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd114;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd116, %r25;
	cvt.u64.u32 	%rd117, %r27;

$L__BB16_13:
	or.b64  	%rd71, %rd116, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB16_15;

	rem.u64 	%rd118, %rd116, %rd53;
	bra.uni 	$L__BB16_16;

$L__BB16_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd116;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd118, %r30;

$L__BB16_16:
	shl.b64 	%rd73, %rd118, 3;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u64 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd115, %rd52;
	add.s64 	%rd77, %rd75, %rd76;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd117;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u64 	%rd83, [%rd82];
	shl.b64 	%rd84, %rd114, 3;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u64 	[%rd85], %rd83;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd114, %r53;
	setp.lt.u64 	%p10, %rd114, %rd50;
	@%p10 bra 	$L__BB16_7;
	bra.uni 	$L__BB16_33;

$L__BB16_17:
	and.b64  	%rd86, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB16_18:
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB16_20;

	div.u64 	%rd120, %rd114, %rd10;
	bra.uni 	$L__BB16_21;

$L__BB16_20:
	cvt.u32.u64 	%r32, %rd114;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd120, %r33;

$L__BB16_21:
	and.b64  	%rd87, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd87, 0;
	@%p12 bra 	$L__BB16_23;

	div.u64 	%rd121, %rd114, %rd54;
	mul.lo.s64 	%rd88, %rd121, %rd54;
	sub.s64 	%rd122, %rd114, %rd88;
	bra.uni 	$L__BB16_24;

$L__BB16_23:
	cvt.u32.u64 	%r35, %rd114;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd121, %r36;
	cvt.u64.u32 	%rd122, %r38;

$L__BB16_24:
	or.b64  	%rd89, %rd121, %rd53;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p13, %rd90, 0;
	@%p13 bra 	$L__BB16_26;

	rem.u64 	%rd123, %rd121, %rd53;
	bra.uni 	$L__BB16_27;

$L__BB16_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd121;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd123, %r41;

$L__BB16_27:
	shl.b64 	%rd91, %rd123, 3;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u64 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd120, %rd52;
	add.s64 	%rd95, %rd93, %rd94;
	mul.lo.s64 	%rd96, %rd95, %rd54;
	add.s64 	%rd124, %rd96, %rd122;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB16_32;

$L__BB16_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd51;
	and.b64  	%rd40, %rd124, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd41, %rd4, %rd100;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd101, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd101, 0;
	@%p15 bra 	$L__BB16_30;

	div.u64 	%rd124, %rd40, %rd42;
	mul.lo.s64 	%rd102, %rd124, %rd42;
	sub.s64 	%rd126, %rd40, %rd102;
	bra.uni 	$L__BB16_31;

$L__BB16_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd124, %r48;
	cvt.u64.u32 	%rd126, %r50;

$L__BB16_31:
	shl.b64 	%rd103, %rd51, 3;
	add.s64 	%rd104, %rd41, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd126;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p16, %rd107, %rd51;
	@%p16 bra 	$L__BB16_28;

$L__BB16_32:
	mul.wide.u32 	%rd108, %r56, 8;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	shl.b64 	%rd111, %rd114, 3;
	add.s64 	%rd112, %rd1, %rd111;
	st.global.u64 	[%rd112], %rd110;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd114, %r53;
	setp.lt.u64 	%p17, %rd114, %rd50;
	@%p17 bra 	$L__BB16_18;

$L__BB16_33:
	ret;

}
	// .globl	is_u32_f32
.visible .entry is_u32_f32(
	.param .u64 is_u32_f32_param_0,
	.param .u64 is_u32_f32_param_1,
	.param .u64 is_u32_f32_param_2,
	.param .u64 is_u32_f32_param_3,
	.param .u64 is_u32_f32_param_4,
	.param .u64 is_u32_f32_param_5,
	.param .u64 is_u32_f32_param_6,
	.param .u64 is_u32_f32_param_7,
	.param .u64 is_u32_f32_param_8,
	.param .u64 is_u32_f32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_u32_f32_param_0];
	ld.param.u64 	%rd51, [is_u32_f32_param_1];
	ld.param.u64 	%rd55, [is_u32_f32_param_2];
	ld.param.u64 	%rd56, [is_u32_f32_param_3];
	ld.param.u64 	%rd57, [is_u32_f32_param_4];
	ld.param.u64 	%rd58, [is_u32_f32_param_5];
	ld.param.u64 	%rd52, [is_u32_f32_param_7];
	ld.param.u64 	%rd53, [is_u32_f32_param_8];
	ld.param.u64 	%rd54, [is_u32_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB17_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB17_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB17_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB17_5;

$L__BB17_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB17_2;

$L__BB17_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB17_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB17_17;

$L__BB17_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB17_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB17_10;

$L__BB17_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB17_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB17_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB17_13;

$L__BB17_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB17_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB17_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB17_16;

$L__BB17_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB17_16:
	shl.b64 	%rd73, %rd116, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f32 	%f1, [%rd82];
	shl.b64 	%rd83, %rd112, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f32 	[%rd84], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB17_7;
	bra.uni 	$L__BB17_33;

$L__BB17_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB17_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB17_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB17_21;

$L__BB17_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB17_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB17_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB17_24;

$L__BB17_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB17_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB17_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB17_27;

$L__BB17_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB17_27:
	shl.b64 	%rd90, %rd121, 2;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u32 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd93, %rd92;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB17_32;

$L__BB17_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB17_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB17_31;

$L__BB17_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB17_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB17_28;

$L__BB17_32:
	mul.wide.u32 	%rd107, %r56, 4;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.f32 	%f2, [%rd108];
	shl.b64 	%rd109, %rd112, 2;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.f32 	[%rd110], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB17_18;

$L__BB17_33:
	ret;

}
	// .globl	is_u32_f64
.visible .entry is_u32_f64(
	.param .u64 is_u32_f64_param_0,
	.param .u64 is_u32_f64_param_1,
	.param .u64 is_u32_f64_param_2,
	.param .u64 is_u32_f64_param_3,
	.param .u64 is_u32_f64_param_4,
	.param .u64 is_u32_f64_param_5,
	.param .u64 is_u32_f64_param_6,
	.param .u64 is_u32_f64_param_7,
	.param .u64 is_u32_f64_param_8,
	.param .u64 is_u32_f64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_u32_f64_param_0];
	ld.param.u64 	%rd51, [is_u32_f64_param_1];
	ld.param.u64 	%rd55, [is_u32_f64_param_2];
	ld.param.u64 	%rd56, [is_u32_f64_param_3];
	ld.param.u64 	%rd57, [is_u32_f64_param_4];
	ld.param.u64 	%rd58, [is_u32_f64_param_5];
	ld.param.u64 	%rd52, [is_u32_f64_param_7];
	ld.param.u64 	%rd53, [is_u32_f64_param_8];
	ld.param.u64 	%rd54, [is_u32_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB18_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB18_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB18_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB18_5;

$L__BB18_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB18_2;

$L__BB18_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB18_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB18_17;

$L__BB18_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB18_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB18_10;

$L__BB18_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB18_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB18_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB18_13;

$L__BB18_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB18_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB18_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB18_16;

$L__BB18_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB18_16:
	shl.b64 	%rd73, %rd116, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.f64 	%fd1, [%rd82];
	shl.b64 	%rd83, %rd112, 3;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.f64 	[%rd84], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB18_7;
	bra.uni 	$L__BB18_33;

$L__BB18_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB18_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB18_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB18_21;

$L__BB18_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB18_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB18_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB18_24;

$L__BB18_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB18_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB18_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB18_27;

$L__BB18_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB18_27:
	shl.b64 	%rd90, %rd121, 2;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u32 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd93, %rd92;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB18_32;

$L__BB18_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd96, %r45;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB18_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB18_31;

$L__BB18_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB18_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r51, %rd105;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd106, %r55;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB18_28;

$L__BB18_32:
	mul.wide.u32 	%rd107, %r56, 8;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.f64 	%fd2, [%rd108];
	shl.b64 	%rd109, %rd112, 3;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.f64 	[%rd110], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB18_18;

$L__BB18_33:
	ret;

}
	// .globl	is_u32_u8
.visible .entry is_u32_u8(
	.param .u64 is_u32_u8_param_0,
	.param .u64 is_u32_u8_param_1,
	.param .u64 is_u32_u8_param_2,
	.param .u64 is_u32_u8_param_3,
	.param .u64 is_u32_u8_param_4,
	.param .u64 is_u32_u8_param_5,
	.param .u64 is_u32_u8_param_6,
	.param .u64 is_u32_u8_param_7,
	.param .u64 is_u32_u8_param_8,
	.param .u64 is_u32_u8_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<122>;


	ld.param.u64 	%rd50, [is_u32_u8_param_0];
	ld.param.u64 	%rd51, [is_u32_u8_param_1];
	ld.param.u64 	%rd55, [is_u32_u8_param_2];
	ld.param.u64 	%rd56, [is_u32_u8_param_3];
	ld.param.u64 	%rd57, [is_u32_u8_param_4];
	ld.param.u64 	%rd58, [is_u32_u8_param_5];
	ld.param.u64 	%rd52, [is_u32_u8_param_7];
	ld.param.u64 	%rd53, [is_u32_u8_param_8];
	ld.param.u64 	%rd54, [is_u32_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB19_5;

	mov.u64 	%rd108, 1;
	mov.u32 	%r52, 0;

$L__BB19_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB19_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd108, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB19_5;

$L__BB19_4:
	mul.lo.s64 	%rd108, %rd7, %rd108;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB19_2;

$L__BB19_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd109, %r53;
	setp.ge.u64 	%p5, %rd109, %rd50;
	@%p5 bra 	$L__BB19_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB19_17;

$L__BB19_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB19_9;

	div.u64 	%rd110, %rd109, %rd10;
	bra.uni 	$L__BB19_10;

$L__BB19_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd109;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd110, %r22;

$L__BB19_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB19_12;

	div.u64 	%rd111, %rd109, %rd54;
	mul.lo.s64 	%rd70, %rd111, %rd54;
	sub.s64 	%rd112, %rd109, %rd70;
	bra.uni 	$L__BB19_13;

$L__BB19_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd109;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd111, %r25;
	cvt.u64.u32 	%rd112, %r27;

$L__BB19_13:
	or.b64  	%rd71, %rd111, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB19_15;

	rem.u64 	%rd113, %rd111, %rd53;
	bra.uni 	$L__BB19_16;

$L__BB19_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd111;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd113, %r30;

$L__BB19_16:
	shl.b64 	%rd73, %rd113, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd110, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd112;
	and.b64  	%rd80, %rd79, 4294967295;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u8 	%rs5, [%rd81];
	add.s64 	%rd82, %rd1, %rd109;
	st.global.u8 	[%rd82], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd109, %r53;
	setp.lt.u64 	%p10, %rd109, %rd50;
	@%p10 bra 	$L__BB19_7;
	bra.uni 	$L__BB19_33;

$L__BB19_17:
	and.b64  	%rd83, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB19_18:
	setp.eq.s64 	%p11, %rd83, 0;
	@%p11 bra 	$L__BB19_20;

	div.u64 	%rd115, %rd109, %rd10;
	bra.uni 	$L__BB19_21;

$L__BB19_20:
	cvt.u32.u64 	%r32, %rd109;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd115, %r33;

$L__BB19_21:
	and.b64  	%rd84, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd84, 0;
	@%p12 bra 	$L__BB19_23;

	div.u64 	%rd116, %rd109, %rd54;
	mul.lo.s64 	%rd85, %rd116, %rd54;
	sub.s64 	%rd117, %rd109, %rd85;
	bra.uni 	$L__BB19_24;

$L__BB19_23:
	cvt.u32.u64 	%r35, %rd109;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd116, %r36;
	cvt.u64.u32 	%rd117, %r38;

$L__BB19_24:
	or.b64  	%rd86, %rd116, %rd53;
	and.b64  	%rd87, %rd86, -4294967296;
	setp.eq.s64 	%p13, %rd87, 0;
	@%p13 bra 	$L__BB19_26;

	rem.u64 	%rd118, %rd116, %rd53;
	bra.uni 	$L__BB19_27;

$L__BB19_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd116;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd118, %r41;

$L__BB19_27:
	shl.b64 	%rd88, %rd118, 2;
	add.s64 	%rd89, %rd3, %rd88;
	ld.global.u32 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd115, %rd52;
	add.s64 	%rd92, %rd91, %rd90;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd119, %rd93, %rd117;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB19_32;

$L__BB19_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd94, %r45;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd119, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB19_30;

	div.u64 	%rd119, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd119, %rd42;
	sub.s64 	%rd121, %rd40, %rd99;
	bra.uni 	$L__BB19_31;

$L__BB19_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd119, %r48;
	cvt.u64.u32 	%rd121, %r50;

$L__BB19_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd121;
	cvt.u32.u64 	%r51, %rd103;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd104, %r55;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB19_28;

$L__BB19_32:
	cvt.u64.u32 	%rd105, %r56;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.u8 	%rs6, [%rd106];
	add.s64 	%rd107, %rd1, %rd109;
	st.global.u8 	[%rd107], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd109, %r53;
	setp.lt.u64 	%p17, %rd109, %rd50;
	@%p17 bra 	$L__BB19_18;

$L__BB19_33:
	ret;

}
	// .globl	is_u32_i64
.visible .entry is_u32_i64(
	.param .u64 is_u32_i64_param_0,
	.param .u64 is_u32_i64_param_1,
	.param .u64 is_u32_i64_param_2,
	.param .u64 is_u32_i64_param_3,
	.param .u64 is_u32_i64_param_4,
	.param .u64 is_u32_i64_param_5,
	.param .u64 is_u32_i64_param_6,
	.param .u64 is_u32_i64_param_7,
	.param .u64 is_u32_i64_param_8,
	.param .u64 is_u32_i64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<127>;


	ld.param.u64 	%rd50, [is_u32_i64_param_0];
	ld.param.u64 	%rd51, [is_u32_i64_param_1];
	ld.param.u64 	%rd55, [is_u32_i64_param_2];
	ld.param.u64 	%rd56, [is_u32_i64_param_3];
	ld.param.u64 	%rd57, [is_u32_i64_param_4];
	ld.param.u64 	%rd58, [is_u32_i64_param_5];
	ld.param.u64 	%rd52, [is_u32_i64_param_7];
	ld.param.u64 	%rd53, [is_u32_i64_param_8];
	ld.param.u64 	%rd54, [is_u32_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB20_5;

	mov.u64 	%rd113, 1;
	mov.u32 	%r52, 0;

$L__BB20_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB20_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd113, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB20_5;

$L__BB20_4:
	mul.lo.s64 	%rd113, %rd7, %rd113;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB20_2;

$L__BB20_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd114, %r53;
	setp.ge.u64 	%p5, %rd114, %rd50;
	@%p5 bra 	$L__BB20_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB20_17;

$L__BB20_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB20_9;

	div.u64 	%rd115, %rd114, %rd10;
	bra.uni 	$L__BB20_10;

$L__BB20_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd114;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd115, %r22;

$L__BB20_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB20_12;

	div.u64 	%rd116, %rd114, %rd54;
	mul.lo.s64 	%rd70, %rd116, %rd54;
	sub.s64 	%rd117, %rd114, %rd70;
	bra.uni 	$L__BB20_13;

$L__BB20_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd114;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd116, %r25;
	cvt.u64.u32 	%rd117, %r27;

$L__BB20_13:
	or.b64  	%rd71, %rd116, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB20_15;

	rem.u64 	%rd118, %rd116, %rd53;
	bra.uni 	$L__BB20_16;

$L__BB20_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd116;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd118, %r30;

$L__BB20_16:
	shl.b64 	%rd73, %rd118, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd115, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd117;
	shl.b64 	%rd80, %rd79, 3;
	and.b64  	%rd81, %rd80, 34359738360;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u64 	%rd83, [%rd82];
	shl.b64 	%rd84, %rd114, 3;
	add.s64 	%rd85, %rd1, %rd84;
	st.global.u64 	[%rd85], %rd83;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd114, %r53;
	setp.lt.u64 	%p10, %rd114, %rd50;
	@%p10 bra 	$L__BB20_7;
	bra.uni 	$L__BB20_33;

$L__BB20_17:
	and.b64  	%rd86, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB20_18:
	setp.eq.s64 	%p11, %rd86, 0;
	@%p11 bra 	$L__BB20_20;

	div.u64 	%rd120, %rd114, %rd10;
	bra.uni 	$L__BB20_21;

$L__BB20_20:
	cvt.u32.u64 	%r32, %rd114;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd120, %r33;

$L__BB20_21:
	and.b64  	%rd87, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd87, 0;
	@%p12 bra 	$L__BB20_23;

	div.u64 	%rd121, %rd114, %rd54;
	mul.lo.s64 	%rd88, %rd121, %rd54;
	sub.s64 	%rd122, %rd114, %rd88;
	bra.uni 	$L__BB20_24;

$L__BB20_23:
	cvt.u32.u64 	%r35, %rd114;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd121, %r36;
	cvt.u64.u32 	%rd122, %r38;

$L__BB20_24:
	or.b64  	%rd89, %rd121, %rd53;
	and.b64  	%rd90, %rd89, -4294967296;
	setp.eq.s64 	%p13, %rd90, 0;
	@%p13 bra 	$L__BB20_26;

	rem.u64 	%rd123, %rd121, %rd53;
	bra.uni 	$L__BB20_27;

$L__BB20_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd121;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd123, %r41;

$L__BB20_27:
	shl.b64 	%rd91, %rd123, 2;
	add.s64 	%rd92, %rd3, %rd91;
	ld.global.u32 	%rd93, [%rd92];
	mul.lo.s64 	%rd94, %rd120, %rd52;
	add.s64 	%rd95, %rd94, %rd93;
	mul.lo.s64 	%rd96, %rd95, %rd54;
	add.s64 	%rd124, %rd96, %rd122;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB20_32;

$L__BB20_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd97, %r45;
	add.s64 	%rd98, %rd97, %rd51;
	and.b64  	%rd40, %rd124, 4294967295;
	shl.b64 	%rd99, %rd98, 3;
	and.b64  	%rd100, %rd99, 34359738360;
	add.s64 	%rd41, %rd4, %rd100;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd101, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd101, 0;
	@%p15 bra 	$L__BB20_30;

	div.u64 	%rd124, %rd40, %rd42;
	mul.lo.s64 	%rd102, %rd124, %rd42;
	sub.s64 	%rd126, %rd40, %rd102;
	bra.uni 	$L__BB20_31;

$L__BB20_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd124, %r48;
	cvt.u64.u32 	%rd126, %r50;

$L__BB20_31:
	shl.b64 	%rd103, %rd51, 3;
	add.s64 	%rd104, %rd41, %rd103;
	ld.global.u64 	%rd105, [%rd104];
	mul.lo.s64 	%rd106, %rd105, %rd126;
	cvt.u32.u64 	%r51, %rd106;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd107, %r55;
	setp.lt.u64 	%p16, %rd107, %rd51;
	@%p16 bra 	$L__BB20_28;

$L__BB20_32:
	mul.wide.u32 	%rd108, %r56, 8;
	add.s64 	%rd109, %rd2, %rd108;
	ld.global.u64 	%rd110, [%rd109];
	shl.b64 	%rd111, %rd114, 3;
	add.s64 	%rd112, %rd1, %rd111;
	st.global.u64 	[%rd112], %rd110;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd114, %r53;
	setp.lt.u64 	%p17, %rd114, %rd50;
	@%p17 bra 	$L__BB20_18;

$L__BB20_33:
	ret;

}
	// .globl	is_u32_u32
.visible .entry is_u32_u32(
	.param .u64 is_u32_u32_param_0,
	.param .u64 is_u32_u32_param_1,
	.param .u64 is_u32_u32_param_2,
	.param .u64 is_u32_u32_param_3,
	.param .u64 is_u32_u32_param_4,
	.param .u64 is_u32_u32_param_5,
	.param .u64 is_u32_u32_param_6,
	.param .u64 is_u32_u32_param_7,
	.param .u64 is_u32_u32_param_8,
	.param .u64 is_u32_u32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_u32_u32_param_0];
	ld.param.u64 	%rd51, [is_u32_u32_param_1];
	ld.param.u64 	%rd55, [is_u32_u32_param_2];
	ld.param.u64 	%rd56, [is_u32_u32_param_3];
	ld.param.u64 	%rd57, [is_u32_u32_param_4];
	ld.param.u64 	%rd58, [is_u32_u32_param_5];
	ld.param.u64 	%rd52, [is_u32_u32_param_7];
	ld.param.u64 	%rd53, [is_u32_u32_param_8];
	ld.param.u64 	%rd54, [is_u32_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB21_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r54, 0;

$L__BB21_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB21_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB21_5;

$L__BB21_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd67, %r54;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB21_2;

$L__BB21_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r55;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB21_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB21_17;

$L__BB21_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB21_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB21_10;

$L__BB21_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB21_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB21_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB21_13;

$L__BB21_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB21_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB21_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB21_16;

$L__BB21_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB21_16:
	shl.b64 	%rd73, %rd116, 2;
	add.s64 	%rd74, %rd3, %rd73;
	ld.global.u32 	%rd75, [%rd74];
	mul.lo.s64 	%rd76, %rd113, %rd52;
	add.s64 	%rd77, %rd76, %rd75;
	mul.lo.s64 	%rd78, %rd77, %rd54;
	add.s64 	%rd79, %rd78, %rd115;
	shl.b64 	%rd80, %rd79, 2;
	and.b64  	%rd81, %rd80, 17179869180;
	add.s64 	%rd82, %rd2, %rd81;
	ld.global.u32 	%r31, [%rd82];
	shl.b64 	%rd83, %rd112, 2;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u32 	[%rd84], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd112, %r55;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB21_7;
	bra.uni 	$L__BB21_33;

$L__BB21_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd54;

$L__BB21_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB21_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB21_21;

$L__BB21_20:
	cvt.u32.u64 	%r33, %rd112;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd118, %r34;

$L__BB21_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB21_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB21_24;

$L__BB21_23:
	cvt.u32.u64 	%r36, %rd112;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd119, %r37;
	cvt.u64.u32 	%rd120, %r39;

$L__BB21_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB21_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB21_27;

$L__BB21_26:
	cvt.u32.u64 	%r40, %rd53;
	cvt.u32.u64 	%r41, %rd119;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd121, %r42;

$L__BB21_27:
	shl.b64 	%rd90, %rd121, 2;
	add.s64 	%rd91, %rd3, %rd90;
	ld.global.u32 	%rd92, [%rd91];
	mul.lo.s64 	%rd93, %rd118, %rd52;
	add.s64 	%rd94, %rd93, %rd92;
	mul.lo.s64 	%rd95, %rd94, %rd54;
	add.s64 	%rd122, %rd95, %rd120;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB21_32;

$L__BB21_28:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd96, %r46;
	add.s64 	%rd97, %rd96, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd98, %rd97, 3;
	and.b64  	%rd99, %rd98, 34359738360;
	add.s64 	%rd41, %rd4, %rd99;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd100, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd100, 0;
	@%p15 bra 	$L__BB21_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd101, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd101;
	bra.uni 	$L__BB21_31;

$L__BB21_30:
	cvt.u32.u64 	%r47, %rd42;
	cvt.u32.u64 	%r48, %rd40;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd122, %r49;
	cvt.u64.u32 	%rd124, %r51;

$L__BB21_31:
	shl.b64 	%rd102, %rd51, 3;
	add.s64 	%rd103, %rd41, %rd102;
	ld.global.u64 	%rd104, [%rd103];
	mul.lo.s64 	%rd105, %rd104, %rd124;
	cvt.u32.u64 	%r52, %rd105;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd106, %r57;
	setp.lt.u64 	%p16, %rd106, %rd51;
	@%p16 bra 	$L__BB21_28;

$L__BB21_32:
	mul.wide.u32 	%rd107, %r58, 4;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u32 	%r53, [%rd108];
	shl.b64 	%rd109, %rd112, 2;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.u32 	[%rd110], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd112, %r55;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB21_18;

$L__BB21_33:
	ret;

}
	// .globl	is_u8_f32
.visible .entry is_u8_f32(
	.param .u64 is_u8_f32_param_0,
	.param .u64 is_u8_f32_param_1,
	.param .u64 is_u8_f32_param_2,
	.param .u64 is_u8_f32_param_3,
	.param .u64 is_u8_f32_param_4,
	.param .u64 is_u8_f32_param_5,
	.param .u64 is_u8_f32_param_6,
	.param .u64 is_u8_f32_param_7,
	.param .u64 is_u8_f32_param_8,
	.param .u64 is_u8_f32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd50, [is_u8_f32_param_0];
	ld.param.u64 	%rd51, [is_u8_f32_param_1];
	ld.param.u64 	%rd55, [is_u8_f32_param_2];
	ld.param.u64 	%rd56, [is_u8_f32_param_3];
	ld.param.u64 	%rd57, [is_u8_f32_param_4];
	ld.param.u64 	%rd58, [is_u8_f32_param_5];
	ld.param.u64 	%rd52, [is_u8_f32_param_7];
	ld.param.u64 	%rd53, [is_u8_f32_param_8];
	ld.param.u64 	%rd54, [is_u8_f32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB22_5;

	mov.u64 	%rd109, 1;
	mov.u32 	%r52, 0;

$L__BB22_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB22_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd109, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB22_5;

$L__BB22_4:
	mul.lo.s64 	%rd109, %rd7, %rd109;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB22_2;

$L__BB22_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r53;
	setp.ge.u64 	%p5, %rd110, %rd50;
	@%p5 bra 	$L__BB22_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB22_17;

$L__BB22_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB22_9;

	div.u64 	%rd111, %rd110, %rd10;
	bra.uni 	$L__BB22_10;

$L__BB22_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB22_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB22_12;

	div.u64 	%rd112, %rd110, %rd54;
	mul.lo.s64 	%rd70, %rd112, %rd54;
	sub.s64 	%rd113, %rd110, %rd70;
	bra.uni 	$L__BB22_13;

$L__BB22_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB22_13:
	or.b64  	%rd71, %rd112, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB22_15;

	rem.u64 	%rd114, %rd112, %rd53;
	bra.uni 	$L__BB22_16;

$L__BB22_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB22_16:
	add.s64 	%rd73, %rd3, %rd114;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd111, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd113;
	shl.b64 	%rd79, %rd78, 2;
	and.b64  	%rd80, %rd79, 17179869180;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.f32 	%f1, [%rd81];
	shl.b64 	%rd82, %rd110, 2;
	add.s64 	%rd83, %rd1, %rd82;
	st.global.f32 	[%rd83], %f1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p10, %rd110, %rd50;
	@%p10 bra 	$L__BB22_7;
	bra.uni 	$L__BB22_33;

$L__BB22_17:
	and.b64  	%rd84, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB22_18:
	setp.eq.s64 	%p11, %rd84, 0;
	@%p11 bra 	$L__BB22_20;

	div.u64 	%rd116, %rd110, %rd10;
	bra.uni 	$L__BB22_21;

$L__BB22_20:
	cvt.u32.u64 	%r32, %rd110;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd116, %r33;

$L__BB22_21:
	and.b64  	%rd85, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd85, 0;
	@%p12 bra 	$L__BB22_23;

	div.u64 	%rd117, %rd110, %rd54;
	mul.lo.s64 	%rd86, %rd117, %rd54;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB22_24;

$L__BB22_23:
	cvt.u32.u64 	%r35, %rd110;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd117, %r36;
	cvt.u64.u32 	%rd118, %r38;

$L__BB22_24:
	or.b64  	%rd87, %rd117, %rd53;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p13, %rd88, 0;
	@%p13 bra 	$L__BB22_26;

	rem.u64 	%rd119, %rd117, %rd53;
	bra.uni 	$L__BB22_27;

$L__BB22_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd117;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd119, %r41;

$L__BB22_27:
	add.s64 	%rd89, %rd3, %rd119;
	ld.global.u8 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd116, %rd52;
	add.s64 	%rd92, %rd91, %rd90;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd120, %rd93, %rd118;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB22_32;

$L__BB22_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd94, %r45;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd120, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB22_30;

	div.u64 	%rd120, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd120, %rd42;
	sub.s64 	%rd122, %rd40, %rd99;
	bra.uni 	$L__BB22_31;

$L__BB22_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd120, %r48;
	cvt.u64.u32 	%rd122, %r50;

$L__BB22_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd122;
	cvt.u32.u64 	%r51, %rd103;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd104, %r55;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB22_28;

$L__BB22_32:
	mul.wide.u32 	%rd105, %r56, 4;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.f32 	%f2, [%rd106];
	shl.b64 	%rd107, %rd110, 2;
	add.s64 	%rd108, %rd1, %rd107;
	st.global.f32 	[%rd108], %f2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p17, %rd110, %rd50;
	@%p17 bra 	$L__BB22_18;

$L__BB22_33:
	ret;

}
	// .globl	is_u8_f64
.visible .entry is_u8_f64(
	.param .u64 is_u8_f64_param_0,
	.param .u64 is_u8_f64_param_1,
	.param .u64 is_u8_f64_param_2,
	.param .u64 is_u8_f64_param_3,
	.param .u64 is_u8_f64_param_4,
	.param .u64 is_u8_f64_param_5,
	.param .u64 is_u8_f64_param_6,
	.param .u64 is_u8_f64_param_7,
	.param .u64 is_u8_f64_param_8,
	.param .u64 is_u8_f64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd50, [is_u8_f64_param_0];
	ld.param.u64 	%rd51, [is_u8_f64_param_1];
	ld.param.u64 	%rd55, [is_u8_f64_param_2];
	ld.param.u64 	%rd56, [is_u8_f64_param_3];
	ld.param.u64 	%rd57, [is_u8_f64_param_4];
	ld.param.u64 	%rd58, [is_u8_f64_param_5];
	ld.param.u64 	%rd52, [is_u8_f64_param_7];
	ld.param.u64 	%rd53, [is_u8_f64_param_8];
	ld.param.u64 	%rd54, [is_u8_f64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB23_5;

	mov.u64 	%rd109, 1;
	mov.u32 	%r52, 0;

$L__BB23_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB23_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd109, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB23_5;

$L__BB23_4:
	mul.lo.s64 	%rd109, %rd7, %rd109;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB23_2;

$L__BB23_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r53;
	setp.ge.u64 	%p5, %rd110, %rd50;
	@%p5 bra 	$L__BB23_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB23_17;

$L__BB23_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB23_9;

	div.u64 	%rd111, %rd110, %rd10;
	bra.uni 	$L__BB23_10;

$L__BB23_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB23_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB23_12;

	div.u64 	%rd112, %rd110, %rd54;
	mul.lo.s64 	%rd70, %rd112, %rd54;
	sub.s64 	%rd113, %rd110, %rd70;
	bra.uni 	$L__BB23_13;

$L__BB23_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB23_13:
	or.b64  	%rd71, %rd112, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB23_15;

	rem.u64 	%rd114, %rd112, %rd53;
	bra.uni 	$L__BB23_16;

$L__BB23_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB23_16:
	add.s64 	%rd73, %rd3, %rd114;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd111, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd113;
	shl.b64 	%rd79, %rd78, 3;
	and.b64  	%rd80, %rd79, 34359738360;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.f64 	%fd1, [%rd81];
	shl.b64 	%rd82, %rd110, 3;
	add.s64 	%rd83, %rd1, %rd82;
	st.global.f64 	[%rd83], %fd1;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p10, %rd110, %rd50;
	@%p10 bra 	$L__BB23_7;
	bra.uni 	$L__BB23_33;

$L__BB23_17:
	and.b64  	%rd84, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB23_18:
	setp.eq.s64 	%p11, %rd84, 0;
	@%p11 bra 	$L__BB23_20;

	div.u64 	%rd116, %rd110, %rd10;
	bra.uni 	$L__BB23_21;

$L__BB23_20:
	cvt.u32.u64 	%r32, %rd110;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd116, %r33;

$L__BB23_21:
	and.b64  	%rd85, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd85, 0;
	@%p12 bra 	$L__BB23_23;

	div.u64 	%rd117, %rd110, %rd54;
	mul.lo.s64 	%rd86, %rd117, %rd54;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB23_24;

$L__BB23_23:
	cvt.u32.u64 	%r35, %rd110;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd117, %r36;
	cvt.u64.u32 	%rd118, %r38;

$L__BB23_24:
	or.b64  	%rd87, %rd117, %rd53;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p13, %rd88, 0;
	@%p13 bra 	$L__BB23_26;

	rem.u64 	%rd119, %rd117, %rd53;
	bra.uni 	$L__BB23_27;

$L__BB23_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd117;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd119, %r41;

$L__BB23_27:
	add.s64 	%rd89, %rd3, %rd119;
	ld.global.u8 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd116, %rd52;
	add.s64 	%rd92, %rd91, %rd90;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd120, %rd93, %rd118;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB23_32;

$L__BB23_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd94, %r45;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd120, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB23_30;

	div.u64 	%rd120, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd120, %rd42;
	sub.s64 	%rd122, %rd40, %rd99;
	bra.uni 	$L__BB23_31;

$L__BB23_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd120, %r48;
	cvt.u64.u32 	%rd122, %r50;

$L__BB23_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd122;
	cvt.u32.u64 	%r51, %rd103;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd104, %r55;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB23_28;

$L__BB23_32:
	mul.wide.u32 	%rd105, %r56, 8;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.f64 	%fd2, [%rd106];
	shl.b64 	%rd107, %rd110, 3;
	add.s64 	%rd108, %rd1, %rd107;
	st.global.f64 	[%rd108], %fd2;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd110, %r53;
	setp.lt.u64 	%p17, %rd110, %rd50;
	@%p17 bra 	$L__BB23_18;

$L__BB23_33:
	ret;

}
	// .globl	is_u8_u8
.visible .entry is_u8_u8(
	.param .u64 is_u8_u8_param_0,
	.param .u64 is_u8_u8_param_1,
	.param .u64 is_u8_u8_param_2,
	.param .u64 is_u8_u8_param_3,
	.param .u64 is_u8_u8_param_4,
	.param .u64 is_u8_u8_param_5,
	.param .u64 is_u8_u8_param_6,
	.param .u64 is_u8_u8_param_7,
	.param .u64 is_u8_u8_param_8,
	.param .u64 is_u8_u8_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<120>;


	ld.param.u64 	%rd50, [is_u8_u8_param_0];
	ld.param.u64 	%rd51, [is_u8_u8_param_1];
	ld.param.u64 	%rd55, [is_u8_u8_param_2];
	ld.param.u64 	%rd56, [is_u8_u8_param_3];
	ld.param.u64 	%rd57, [is_u8_u8_param_4];
	ld.param.u64 	%rd58, [is_u8_u8_param_5];
	ld.param.u64 	%rd52, [is_u8_u8_param_7];
	ld.param.u64 	%rd53, [is_u8_u8_param_8];
	ld.param.u64 	%rd54, [is_u8_u8_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs7, %rs2;
	@%p1 bra 	$L__BB24_5;

	mov.u64 	%rd106, 1;
	mov.u32 	%r52, 0;

$L__BB24_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB24_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd106, %rd66;
	mov.u16 	%rs7, 0;
	@%p3 bra 	$L__BB24_5;

$L__BB24_4:
	mul.lo.s64 	%rd106, %rd7, %rd106;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs7, %rs2;
	@%p4 bra 	$L__BB24_2;

$L__BB24_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd107, %r53;
	setp.ge.u64 	%p5, %rd107, %rd50;
	@%p5 bra 	$L__BB24_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs7, 0;
	@%p6 bra 	$L__BB24_17;

$L__BB24_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB24_9;

	div.u64 	%rd108, %rd107, %rd10;
	bra.uni 	$L__BB24_10;

$L__BB24_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd107;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd108, %r22;

$L__BB24_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB24_12;

	div.u64 	%rd109, %rd107, %rd54;
	mul.lo.s64 	%rd70, %rd109, %rd54;
	sub.s64 	%rd110, %rd107, %rd70;
	bra.uni 	$L__BB24_13;

$L__BB24_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd107;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd109, %r25;
	cvt.u64.u32 	%rd110, %r27;

$L__BB24_13:
	or.b64  	%rd71, %rd109, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB24_15;

	rem.u64 	%rd111, %rd109, %rd53;
	bra.uni 	$L__BB24_16;

$L__BB24_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd109;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd111, %r30;

$L__BB24_16:
	add.s64 	%rd73, %rd3, %rd111;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd108, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd110;
	and.b64  	%rd79, %rd78, 4294967295;
	add.s64 	%rd80, %rd2, %rd79;
	ld.global.u8 	%rs5, [%rd80];
	add.s64 	%rd81, %rd1, %rd107;
	st.global.u8 	[%rd81], %rs5;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd107, %r53;
	setp.lt.u64 	%p10, %rd107, %rd50;
	@%p10 bra 	$L__BB24_7;
	bra.uni 	$L__BB24_33;

$L__BB24_17:
	and.b64  	%rd82, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB24_18:
	setp.eq.s64 	%p11, %rd82, 0;
	@%p11 bra 	$L__BB24_20;

	div.u64 	%rd113, %rd107, %rd10;
	bra.uni 	$L__BB24_21;

$L__BB24_20:
	cvt.u32.u64 	%r32, %rd107;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd113, %r33;

$L__BB24_21:
	and.b64  	%rd83, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd83, 0;
	@%p12 bra 	$L__BB24_23;

	div.u64 	%rd114, %rd107, %rd54;
	mul.lo.s64 	%rd84, %rd114, %rd54;
	sub.s64 	%rd115, %rd107, %rd84;
	bra.uni 	$L__BB24_24;

$L__BB24_23:
	cvt.u32.u64 	%r35, %rd107;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd114, %r36;
	cvt.u64.u32 	%rd115, %r38;

$L__BB24_24:
	or.b64  	%rd85, %rd114, %rd53;
	and.b64  	%rd86, %rd85, -4294967296;
	setp.eq.s64 	%p13, %rd86, 0;
	@%p13 bra 	$L__BB24_26;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB24_27;

$L__BB24_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd114;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd116, %r41;

$L__BB24_27:
	add.s64 	%rd87, %rd3, %rd116;
	ld.global.u8 	%rd88, [%rd87];
	mul.lo.s64 	%rd89, %rd113, %rd52;
	add.s64 	%rd90, %rd89, %rd88;
	mul.lo.s64 	%rd91, %rd90, %rd54;
	add.s64 	%rd117, %rd91, %rd115;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB24_32;

$L__BB24_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd92, %r45;
	add.s64 	%rd93, %rd92, %rd51;
	and.b64  	%rd40, %rd117, 4294967295;
	shl.b64 	%rd94, %rd93, 3;
	and.b64  	%rd95, %rd94, 34359738360;
	add.s64 	%rd41, %rd4, %rd95;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd96, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd96, 0;
	@%p15 bra 	$L__BB24_30;

	div.u64 	%rd117, %rd40, %rd42;
	mul.lo.s64 	%rd97, %rd117, %rd42;
	sub.s64 	%rd119, %rd40, %rd97;
	bra.uni 	$L__BB24_31;

$L__BB24_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd117, %r48;
	cvt.u64.u32 	%rd119, %r50;

$L__BB24_31:
	shl.b64 	%rd98, %rd51, 3;
	add.s64 	%rd99, %rd41, %rd98;
	ld.global.u64 	%rd100, [%rd99];
	mul.lo.s64 	%rd101, %rd100, %rd119;
	cvt.u32.u64 	%r51, %rd101;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd102, %r55;
	setp.lt.u64 	%p16, %rd102, %rd51;
	@%p16 bra 	$L__BB24_28;

$L__BB24_32:
	cvt.u64.u32 	%rd103, %r56;
	add.s64 	%rd104, %rd2, %rd103;
	ld.global.u8 	%rs6, [%rd104];
	add.s64 	%rd105, %rd1, %rd107;
	st.global.u8 	[%rd105], %rs6;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd107, %r53;
	setp.lt.u64 	%p17, %rd107, %rd50;
	@%p17 bra 	$L__BB24_18;

$L__BB24_33:
	ret;

}
	// .globl	is_u8_u32
.visible .entry is_u8_u32(
	.param .u64 is_u8_u32_param_0,
	.param .u64 is_u8_u32_param_1,
	.param .u64 is_u8_u32_param_2,
	.param .u64 is_u8_u32_param_3,
	.param .u64 is_u8_u32_param_4,
	.param .u64 is_u8_u32_param_5,
	.param .u64 is_u8_u32_param_6,
	.param .u64 is_u8_u32_param_7,
	.param .u64 is_u8_u32_param_8,
	.param .u64 is_u8_u32_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<59>;
	.reg .b64 	%rd<123>;


	ld.param.u64 	%rd50, [is_u8_u32_param_0];
	ld.param.u64 	%rd51, [is_u8_u32_param_1];
	ld.param.u64 	%rd55, [is_u8_u32_param_2];
	ld.param.u64 	%rd56, [is_u8_u32_param_3];
	ld.param.u64 	%rd57, [is_u8_u32_param_4];
	ld.param.u64 	%rd58, [is_u8_u32_param_5];
	ld.param.u64 	%rd52, [is_u8_u32_param_7];
	ld.param.u64 	%rd53, [is_u8_u32_param_8];
	ld.param.u64 	%rd54, [is_u8_u32_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB25_5;

	mov.u64 	%rd109, 1;
	mov.u32 	%r54, 0;

$L__BB25_2:
	not.b32 	%r16, %r54;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB25_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd109, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB25_5;

$L__BB25_4:
	mul.lo.s64 	%rd109, %rd7, %rd109;
	add.s32 	%r54, %r54, 1;
	cvt.u64.u32 	%rd67, %r54;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB25_2;

$L__BB25_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r55, %r17, %r3, %r18;
	cvt.u64.u32 	%rd110, %r55;
	setp.ge.u64 	%p5, %rd110, %rd50;
	@%p5 bra 	$L__BB25_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB25_17;

$L__BB25_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB25_9;

	div.u64 	%rd111, %rd110, %rd10;
	bra.uni 	$L__BB25_10;

$L__BB25_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd110;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd111, %r22;

$L__BB25_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB25_12;

	div.u64 	%rd112, %rd110, %rd54;
	mul.lo.s64 	%rd70, %rd112, %rd54;
	sub.s64 	%rd113, %rd110, %rd70;
	bra.uni 	$L__BB25_13;

$L__BB25_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd110;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd112, %r25;
	cvt.u64.u32 	%rd113, %r27;

$L__BB25_13:
	or.b64  	%rd71, %rd112, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB25_15;

	rem.u64 	%rd114, %rd112, %rd53;
	bra.uni 	$L__BB25_16;

$L__BB25_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd112;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd114, %r30;

$L__BB25_16:
	add.s64 	%rd73, %rd3, %rd114;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd111, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd113;
	shl.b64 	%rd79, %rd78, 2;
	and.b64  	%rd80, %rd79, 17179869180;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u32 	%r31, [%rd81];
	shl.b64 	%rd82, %rd110, 2;
	add.s64 	%rd83, %rd1, %rd82;
	st.global.u32 	[%rd83], %r31;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd110, %r55;
	setp.lt.u64 	%p10, %rd110, %rd50;
	@%p10 bra 	$L__BB25_7;
	bra.uni 	$L__BB25_33;

$L__BB25_17:
	and.b64  	%rd84, %rd10, -4294967296;
	cvt.u32.u64 	%r32, %rd10;
	cvt.u32.u64 	%r35, %rd54;

$L__BB25_18:
	setp.eq.s64 	%p11, %rd84, 0;
	@%p11 bra 	$L__BB25_20;

	div.u64 	%rd116, %rd110, %rd10;
	bra.uni 	$L__BB25_21;

$L__BB25_20:
	cvt.u32.u64 	%r33, %rd110;
	div.u32 	%r34, %r33, %r32;
	cvt.u64.u32 	%rd116, %r34;

$L__BB25_21:
	and.b64  	%rd85, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd85, 0;
	@%p12 bra 	$L__BB25_23;

	div.u64 	%rd117, %rd110, %rd54;
	mul.lo.s64 	%rd86, %rd117, %rd54;
	sub.s64 	%rd118, %rd110, %rd86;
	bra.uni 	$L__BB25_24;

$L__BB25_23:
	cvt.u32.u64 	%r36, %rd110;
	div.u32 	%r37, %r36, %r35;
	mul.lo.s32 	%r38, %r37, %r35;
	sub.s32 	%r39, %r36, %r38;
	cvt.u64.u32 	%rd117, %r37;
	cvt.u64.u32 	%rd118, %r39;

$L__BB25_24:
	or.b64  	%rd87, %rd117, %rd53;
	and.b64  	%rd88, %rd87, -4294967296;
	setp.eq.s64 	%p13, %rd88, 0;
	@%p13 bra 	$L__BB25_26;

	rem.u64 	%rd119, %rd117, %rd53;
	bra.uni 	$L__BB25_27;

$L__BB25_26:
	cvt.u32.u64 	%r40, %rd53;
	cvt.u32.u64 	%r41, %rd117;
	rem.u32 	%r42, %r41, %r40;
	cvt.u64.u32 	%rd119, %r42;

$L__BB25_27:
	add.s64 	%rd89, %rd3, %rd119;
	ld.global.u8 	%rd90, [%rd89];
	mul.lo.s64 	%rd91, %rd116, %rd52;
	add.s64 	%rd92, %rd91, %rd90;
	mul.lo.s64 	%rd93, %rd92, %rd54;
	add.s64 	%rd120, %rd93, %rd118;
	mov.u32 	%r57, 0;
	mov.u32 	%r58, %r57;
	@%p1 bra 	$L__BB25_32;

$L__BB25_28:
	not.b32 	%r46, %r57;
	cvt.u64.u32 	%rd94, %r46;
	add.s64 	%rd95, %rd94, %rd51;
	and.b64  	%rd40, %rd120, 4294967295;
	shl.b64 	%rd96, %rd95, 3;
	and.b64  	%rd97, %rd96, 34359738360;
	add.s64 	%rd41, %rd4, %rd97;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd98, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd98, 0;
	@%p15 bra 	$L__BB25_30;

	div.u64 	%rd120, %rd40, %rd42;
	mul.lo.s64 	%rd99, %rd120, %rd42;
	sub.s64 	%rd122, %rd40, %rd99;
	bra.uni 	$L__BB25_31;

$L__BB25_30:
	cvt.u32.u64 	%r47, %rd42;
	cvt.u32.u64 	%r48, %rd40;
	div.u32 	%r49, %r48, %r47;
	mul.lo.s32 	%r50, %r49, %r47;
	sub.s32 	%r51, %r48, %r50;
	cvt.u64.u32 	%rd120, %r49;
	cvt.u64.u32 	%rd122, %r51;

$L__BB25_31:
	shl.b64 	%rd100, %rd51, 3;
	add.s64 	%rd101, %rd41, %rd100;
	ld.global.u64 	%rd102, [%rd101];
	mul.lo.s64 	%rd103, %rd102, %rd122;
	cvt.u32.u64 	%r52, %rd103;
	add.s32 	%r58, %r58, %r52;
	add.s32 	%r57, %r57, 1;
	cvt.u64.u32 	%rd104, %r57;
	setp.lt.u64 	%p16, %rd104, %rd51;
	@%p16 bra 	$L__BB25_28;

$L__BB25_32:
	mul.wide.u32 	%rd105, %r58, 4;
	add.s64 	%rd106, %rd2, %rd105;
	ld.global.u32 	%r53, [%rd106];
	shl.b64 	%rd107, %rd110, 2;
	add.s64 	%rd108, %rd1, %rd107;
	st.global.u32 	[%rd108], %r53;
	add.s32 	%r55, %r55, %r5;
	cvt.u64.u32 	%rd110, %r55;
	setp.lt.u64 	%p17, %rd110, %rd50;
	@%p17 bra 	$L__BB25_18;

$L__BB25_33:
	ret;

}
	// .globl	is_u8_i64
.visible .entry is_u8_i64(
	.param .u64 is_u8_i64_param_0,
	.param .u64 is_u8_i64_param_1,
	.param .u64 is_u8_i64_param_2,
	.param .u64 is_u8_i64_param_3,
	.param .u64 is_u8_i64_param_4,
	.param .u64 is_u8_i64_param_5,
	.param .u64 is_u8_i64_param_6,
	.param .u64 is_u8_i64_param_7,
	.param .u64 is_u8_i64_param_8,
	.param .u64 is_u8_i64_param_9
)
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<57>;
	.reg .b64 	%rd<125>;


	ld.param.u64 	%rd50, [is_u8_i64_param_0];
	ld.param.u64 	%rd51, [is_u8_i64_param_1];
	ld.param.u64 	%rd55, [is_u8_i64_param_2];
	ld.param.u64 	%rd56, [is_u8_i64_param_3];
	ld.param.u64 	%rd57, [is_u8_i64_param_4];
	ld.param.u64 	%rd58, [is_u8_i64_param_5];
	ld.param.u64 	%rd52, [is_u8_i64_param_7];
	ld.param.u64 	%rd53, [is_u8_i64_param_8];
	ld.param.u64 	%rd54, [is_u8_i64_param_9];
	cvta.to.global.u64 	%rd1, %rd58;
	cvta.to.global.u64 	%rd2, %rd57;
	cvta.to.global.u64 	%rd3, %rd56;
	cvta.to.global.u64 	%rd4, %rd55;
	setp.eq.s64 	%p1, %rd51, 0;
	mov.u16 	%rs2, 1;
	mov.u16 	%rs5, %rs2;
	@%p1 bra 	$L__BB26_5;

	mov.u64 	%rd111, 1;
	mov.u32 	%r52, 0;

$L__BB26_2:
	not.b32 	%r16, %r52;
	cvt.u64.u32 	%rd60, %r16;
	add.s64 	%rd61, %rd60, %rd51;
	shl.b64 	%rd62, %rd61, 3;
	and.b64  	%rd63, %rd62, 34359738360;
	add.s64 	%rd6, %rd4, %rd63;
	ld.global.u64 	%rd7, [%rd6];
	setp.lt.u64 	%p2, %rd7, 2;
	@%p2 bra 	$L__BB26_4;

	shl.b64 	%rd64, %rd51, 3;
	add.s64 	%rd65, %rd6, %rd64;
	ld.global.u64 	%rd66, [%rd65];
	setp.ne.s64 	%p3, %rd111, %rd66;
	mov.u16 	%rs5, 0;
	@%p3 bra 	$L__BB26_5;

$L__BB26_4:
	mul.lo.s64 	%rd111, %rd7, %rd111;
	add.s32 	%r52, %r52, 1;
	cvt.u64.u32 	%rd67, %r52;
	setp.lt.u64 	%p4, %rd67, %rd51;
	mov.u16 	%rs5, %rs2;
	@%p4 bra 	$L__BB26_2;

$L__BB26_5:
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %tid.x;
	mad.lo.s32 	%r53, %r17, %r3, %r18;
	cvt.u64.u32 	%rd112, %r53;
	setp.ge.u64 	%p5, %rd112, %rd50;
	@%p5 bra 	$L__BB26_33;

	mul.lo.s64 	%rd10, %rd54, %rd53;
	mov.u32 	%r19, %nctaid.x;
	mul.lo.s32 	%r5, %r3, %r19;
	setp.eq.s16 	%p6, %rs5, 0;
	@%p6 bra 	$L__BB26_17;

$L__BB26_7:
	and.b64  	%rd68, %rd10, -4294967296;
	setp.eq.s64 	%p7, %rd68, 0;
	@%p7 bra 	$L__BB26_9;

	div.u64 	%rd113, %rd112, %rd10;
	bra.uni 	$L__BB26_10;

$L__BB26_9:
	cvt.u32.u64 	%r20, %rd10;
	cvt.u32.u64 	%r21, %rd112;
	div.u32 	%r22, %r21, %r20;
	cvt.u64.u32 	%rd113, %r22;

$L__BB26_10:
	and.b64  	%rd69, %rd54, -4294967296;
	setp.eq.s64 	%p8, %rd69, 0;
	@%p8 bra 	$L__BB26_12;

	div.u64 	%rd114, %rd112, %rd54;
	mul.lo.s64 	%rd70, %rd114, %rd54;
	sub.s64 	%rd115, %rd112, %rd70;
	bra.uni 	$L__BB26_13;

$L__BB26_12:
	cvt.u32.u64 	%r23, %rd54;
	cvt.u32.u64 	%r24, %rd112;
	div.u32 	%r25, %r24, %r23;
	mul.lo.s32 	%r26, %r25, %r23;
	sub.s32 	%r27, %r24, %r26;
	cvt.u64.u32 	%rd114, %r25;
	cvt.u64.u32 	%rd115, %r27;

$L__BB26_13:
	or.b64  	%rd71, %rd114, %rd53;
	and.b64  	%rd72, %rd71, -4294967296;
	setp.eq.s64 	%p9, %rd72, 0;
	@%p9 bra 	$L__BB26_15;

	rem.u64 	%rd116, %rd114, %rd53;
	bra.uni 	$L__BB26_16;

$L__BB26_15:
	cvt.u32.u64 	%r28, %rd53;
	cvt.u32.u64 	%r29, %rd114;
	rem.u32 	%r30, %r29, %r28;
	cvt.u64.u32 	%rd116, %r30;

$L__BB26_16:
	add.s64 	%rd73, %rd3, %rd116;
	ld.global.u8 	%rd74, [%rd73];
	mul.lo.s64 	%rd75, %rd113, %rd52;
	add.s64 	%rd76, %rd75, %rd74;
	mul.lo.s64 	%rd77, %rd76, %rd54;
	add.s64 	%rd78, %rd77, %rd115;
	shl.b64 	%rd79, %rd78, 3;
	and.b64  	%rd80, %rd79, 34359738360;
	add.s64 	%rd81, %rd2, %rd80;
	ld.global.u64 	%rd82, [%rd81];
	shl.b64 	%rd83, %rd112, 3;
	add.s64 	%rd84, %rd1, %rd83;
	st.global.u64 	[%rd84], %rd82;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p10, %rd112, %rd50;
	@%p10 bra 	$L__BB26_7;
	bra.uni 	$L__BB26_33;

$L__BB26_17:
	and.b64  	%rd85, %rd10, -4294967296;
	cvt.u32.u64 	%r31, %rd10;
	cvt.u32.u64 	%r34, %rd54;

$L__BB26_18:
	setp.eq.s64 	%p11, %rd85, 0;
	@%p11 bra 	$L__BB26_20;

	div.u64 	%rd118, %rd112, %rd10;
	bra.uni 	$L__BB26_21;

$L__BB26_20:
	cvt.u32.u64 	%r32, %rd112;
	div.u32 	%r33, %r32, %r31;
	cvt.u64.u32 	%rd118, %r33;

$L__BB26_21:
	and.b64  	%rd86, %rd54, -4294967296;
	setp.eq.s64 	%p12, %rd86, 0;
	@%p12 bra 	$L__BB26_23;

	div.u64 	%rd119, %rd112, %rd54;
	mul.lo.s64 	%rd87, %rd119, %rd54;
	sub.s64 	%rd120, %rd112, %rd87;
	bra.uni 	$L__BB26_24;

$L__BB26_23:
	cvt.u32.u64 	%r35, %rd112;
	div.u32 	%r36, %r35, %r34;
	mul.lo.s32 	%r37, %r36, %r34;
	sub.s32 	%r38, %r35, %r37;
	cvt.u64.u32 	%rd119, %r36;
	cvt.u64.u32 	%rd120, %r38;

$L__BB26_24:
	or.b64  	%rd88, %rd119, %rd53;
	and.b64  	%rd89, %rd88, -4294967296;
	setp.eq.s64 	%p13, %rd89, 0;
	@%p13 bra 	$L__BB26_26;

	rem.u64 	%rd121, %rd119, %rd53;
	bra.uni 	$L__BB26_27;

$L__BB26_26:
	cvt.u32.u64 	%r39, %rd53;
	cvt.u32.u64 	%r40, %rd119;
	rem.u32 	%r41, %r40, %r39;
	cvt.u64.u32 	%rd121, %r41;

$L__BB26_27:
	add.s64 	%rd90, %rd3, %rd121;
	ld.global.u8 	%rd91, [%rd90];
	mul.lo.s64 	%rd92, %rd118, %rd52;
	add.s64 	%rd93, %rd92, %rd91;
	mul.lo.s64 	%rd94, %rd93, %rd54;
	add.s64 	%rd122, %rd94, %rd120;
	mov.u32 	%r55, 0;
	mov.u32 	%r56, %r55;
	@%p1 bra 	$L__BB26_32;

$L__BB26_28:
	not.b32 	%r45, %r55;
	cvt.u64.u32 	%rd95, %r45;
	add.s64 	%rd96, %rd95, %rd51;
	and.b64  	%rd40, %rd122, 4294967295;
	shl.b64 	%rd97, %rd96, 3;
	and.b64  	%rd98, %rd97, 34359738360;
	add.s64 	%rd41, %rd4, %rd98;
	ld.global.u64 	%rd42, [%rd41];
	and.b64  	%rd99, %rd42, -4294967296;
	setp.eq.s64 	%p15, %rd99, 0;
	@%p15 bra 	$L__BB26_30;

	div.u64 	%rd122, %rd40, %rd42;
	mul.lo.s64 	%rd100, %rd122, %rd42;
	sub.s64 	%rd124, %rd40, %rd100;
	bra.uni 	$L__BB26_31;

$L__BB26_30:
	cvt.u32.u64 	%r46, %rd42;
	cvt.u32.u64 	%r47, %rd40;
	div.u32 	%r48, %r47, %r46;
	mul.lo.s32 	%r49, %r48, %r46;
	sub.s32 	%r50, %r47, %r49;
	cvt.u64.u32 	%rd122, %r48;
	cvt.u64.u32 	%rd124, %r50;

$L__BB26_31:
	shl.b64 	%rd101, %rd51, 3;
	add.s64 	%rd102, %rd41, %rd101;
	ld.global.u64 	%rd103, [%rd102];
	mul.lo.s64 	%rd104, %rd103, %rd124;
	cvt.u32.u64 	%r51, %rd104;
	add.s32 	%r56, %r56, %r51;
	add.s32 	%r55, %r55, 1;
	cvt.u64.u32 	%rd105, %r55;
	setp.lt.u64 	%p16, %rd105, %rd51;
	@%p16 bra 	$L__BB26_28;

$L__BB26_32:
	mul.wide.u32 	%rd106, %r56, 8;
	add.s64 	%rd107, %rd2, %rd106;
	ld.global.u64 	%rd108, [%rd107];
	shl.b64 	%rd109, %rd112, 3;
	add.s64 	%rd110, %rd1, %rd109;
	st.global.u64 	[%rd110], %rd108;
	add.s32 	%r53, %r53, %r5;
	cvt.u64.u32 	%rd112, %r53;
	setp.lt.u64 	%p17, %rd112, %rd50;
	@%p17 bra 	$L__BB26_18;

$L__BB26_33:
	ret;

}
	// .globl	gather_i64_f32
.visible .entry gather_i64_f32(
	.param .u64 gather_i64_f32_param_0,
	.param .u64 gather_i64_f32_param_1,
	.param .u64 gather_i64_f32_param_2,
	.param .u64 gather_i64_f32_param_3,
	.param .u64 gather_i64_f32_param_4,
	.param .u64 gather_i64_f32_param_5,
	.param .u64 gather_i64_f32_param_6,
	.param .u64 gather_i64_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f32_param_0];
	ld.param.u64 	%rd16, [gather_i64_f32_param_1];
	ld.param.u64 	%rd17, [gather_i64_f32_param_2];
	ld.param.u64 	%rd18, [gather_i64_f32_param_3];
	ld.param.u64 	%rd19, [gather_i64_f32_param_5];
	ld.param.u64 	%rd20, [gather_i64_f32_param_6];
	ld.param.u64 	%rd21, [gather_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB27_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB27_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB27_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB27_5;

$L__BB27_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB27_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB27_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB27_8;

$L__BB27_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB27_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB27_2;

$L__BB27_9:
	ret;

}
	// .globl	gather_i64_f64
.visible .entry gather_i64_f64(
	.param .u64 gather_i64_f64_param_0,
	.param .u64 gather_i64_f64_param_1,
	.param .u64 gather_i64_f64_param_2,
	.param .u64 gather_i64_f64_param_3,
	.param .u64 gather_i64_f64_param_4,
	.param .u64 gather_i64_f64_param_5,
	.param .u64 gather_i64_f64_param_6,
	.param .u64 gather_i64_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_f64_param_0];
	ld.param.u64 	%rd16, [gather_i64_f64_param_1];
	ld.param.u64 	%rd17, [gather_i64_f64_param_2];
	ld.param.u64 	%rd18, [gather_i64_f64_param_3];
	ld.param.u64 	%rd19, [gather_i64_f64_param_5];
	ld.param.u64 	%rd20, [gather_i64_f64_param_6];
	ld.param.u64 	%rd21, [gather_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB28_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB28_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB28_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB28_5;

$L__BB28_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB28_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB28_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB28_8;

$L__BB28_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB28_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	add.s64 	%rd33, %rd5, %rd23;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB28_2;

$L__BB28_9:
	ret;

}
	// .globl	gather_i64_u8
.visible .entry gather_i64_u8(
	.param .u64 gather_i64_u8_param_0,
	.param .u64 gather_i64_u8_param_1,
	.param .u64 gather_i64_u8_param_2,
	.param .u64 gather_i64_u8_param_3,
	.param .u64 gather_i64_u8_param_4,
	.param .u64 gather_i64_u8_param_5,
	.param .u64 gather_i64_u8_param_6,
	.param .u64 gather_i64_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd15, [gather_i64_u8_param_0];
	ld.param.u64 	%rd16, [gather_i64_u8_param_1];
	ld.param.u64 	%rd17, [gather_i64_u8_param_2];
	ld.param.u64 	%rd18, [gather_i64_u8_param_3];
	ld.param.u64 	%rd19, [gather_i64_u8_param_5];
	ld.param.u64 	%rd20, [gather_i64_u8_param_6];
	ld.param.u64 	%rd21, [gather_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd32, %r15;
	setp.ge.u64 	%p1, %rd32, %rd15;
	@%p1 bra 	$L__BB29_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB29_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB29_4;

	rem.u64 	%rd33, %rd32, %rd21;
	bra.uni 	$L__BB29_5;

$L__BB29_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd32;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd33, %r11;

$L__BB29_5:
	shl.b64 	%rd23, %rd32, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB29_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB29_8;

$L__BB29_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd32;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd34, %r14;

$L__BB29_8:
	mul.lo.s64 	%rd26, %rd34, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs1, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd32, %r15;
	setp.lt.u64 	%p4, %rd32, %rd15;
	@%p4 bra 	$L__BB29_2;

$L__BB29_9:
	ret;

}
	// .globl	gather_i64_u32
.visible .entry gather_i64_u32(
	.param .u64 gather_i64_u32_param_0,
	.param .u64 gather_i64_u32_param_1,
	.param .u64 gather_i64_u32_param_2,
	.param .u64 gather_i64_u32_param_3,
	.param .u64 gather_i64_u32_param_4,
	.param .u64 gather_i64_u32_param_5,
	.param .u64 gather_i64_u32_param_6,
	.param .u64 gather_i64_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd15, [gather_i64_u32_param_0];
	ld.param.u64 	%rd16, [gather_i64_u32_param_1];
	ld.param.u64 	%rd17, [gather_i64_u32_param_2];
	ld.param.u64 	%rd18, [gather_i64_u32_param_3];
	ld.param.u64 	%rd19, [gather_i64_u32_param_5];
	ld.param.u64 	%rd20, [gather_i64_u32_param_6];
	ld.param.u64 	%rd21, [gather_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd15;
	@%p1 bra 	$L__BB30_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB30_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB30_4;

	rem.u64 	%rd35, %rd34, %rd21;
	bra.uni 	$L__BB30_5;

$L__BB30_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB30_5:
	shl.b64 	%rd23, %rd34, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB30_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB30_8;

$L__BB30_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB30_8:
	mul.lo.s64 	%rd26, %rd36, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r15, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u32 	[%rd33], %r15;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd15;
	@%p4 bra 	$L__BB30_2;

$L__BB30_9:
	ret;

}
	// .globl	gather_i64_i64
.visible .entry gather_i64_i64(
	.param .u64 gather_i64_i64_param_0,
	.param .u64 gather_i64_i64_param_1,
	.param .u64 gather_i64_i64_param_2,
	.param .u64 gather_i64_i64_param_3,
	.param .u64 gather_i64_i64_param_4,
	.param .u64 gather_i64_i64_param_5,
	.param .u64 gather_i64_i64_param_6,
	.param .u64 gather_i64_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd15, [gather_i64_i64_param_0];
	ld.param.u64 	%rd16, [gather_i64_i64_param_1];
	ld.param.u64 	%rd17, [gather_i64_i64_param_2];
	ld.param.u64 	%rd18, [gather_i64_i64_param_3];
	ld.param.u64 	%rd19, [gather_i64_i64_param_5];
	ld.param.u64 	%rd20, [gather_i64_i64_param_6];
	ld.param.u64 	%rd21, [gather_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd35, %r15;
	setp.ge.u64 	%p1, %rd35, %rd15;
	@%p1 bra 	$L__BB31_9;

	mul.lo.s64 	%rd2, %rd21, %rd20;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd16;
	cvta.to.global.u64 	%rd4, %rd17;
	cvta.to.global.u64 	%rd5, %rd18;

$L__BB31_2:
	and.b64  	%rd22, %rd21, -4294967296;
	setp.eq.s64 	%p2, %rd22, 0;
	@%p2 bra 	$L__BB31_4;

	rem.u64 	%rd36, %rd35, %rd21;
	bra.uni 	$L__BB31_5;

$L__BB31_4:
	cvt.u32.u64 	%r9, %rd21;
	cvt.u32.u64 	%r10, %rd35;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd36, %r11;

$L__BB31_5:
	shl.b64 	%rd23, %rd35, 3;
	add.s64 	%rd24, %rd3, %rd23;
	ld.global.u64 	%rd10, [%rd24];
	and.b64  	%rd25, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB31_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB31_8;

$L__BB31_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd35;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd37, %r14;

$L__BB31_8:
	mul.lo.s64 	%rd26, %rd37, %rd19;
	add.s64 	%rd27, %rd26, %rd10;
	mul.lo.s64 	%rd28, %rd27, %rd21;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	add.s64 	%rd34, %rd5, %rd23;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd35, %r15;
	setp.lt.u64 	%p4, %rd35, %rd15;
	@%p4 bra 	$L__BB31_2;

$L__BB31_9:
	ret;

}
	// .globl	gather_u32_f32
.visible .entry gather_u32_f32(
	.param .u64 gather_u32_f32_param_0,
	.param .u64 gather_u32_f32_param_1,
	.param .u64 gather_u32_f32_param_2,
	.param .u64 gather_u32_f32_param_3,
	.param .u64 gather_u32_f32_param_4,
	.param .u64 gather_u32_f32_param_5,
	.param .u64 gather_u32_f32_param_6,
	.param .u64 gather_u32_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f32_param_0];
	ld.param.u64 	%rd15, [gather_u32_f32_param_1];
	ld.param.u64 	%rd16, [gather_u32_f32_param_2];
	ld.param.u64 	%rd17, [gather_u32_f32_param_3];
	ld.param.u64 	%rd18, [gather_u32_f32_param_5];
	ld.param.u64 	%rd19, [gather_u32_f32_param_6];
	ld.param.u64 	%rd20, [gather_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB32_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB32_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB32_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB32_5;

$L__BB32_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB32_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB32_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB32_8;

$L__BB32_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB32_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	add.s64 	%rd33, %rd5, %rd22;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB32_2;

$L__BB32_9:
	ret;

}
	// .globl	gather_u32_f64
.visible .entry gather_u32_f64(
	.param .u64 gather_u32_f64_param_0,
	.param .u64 gather_u32_f64_param_1,
	.param .u64 gather_u32_f64_param_2,
	.param .u64 gather_u32_f64_param_3,
	.param .u64 gather_u32_f64_param_4,
	.param .u64 gather_u32_f64_param_5,
	.param .u64 gather_u32_f64_param_6,
	.param .u64 gather_u32_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_f64_param_0];
	ld.param.u64 	%rd15, [gather_u32_f64_param_1];
	ld.param.u64 	%rd16, [gather_u32_f64_param_2];
	ld.param.u64 	%rd17, [gather_u32_f64_param_3];
	ld.param.u64 	%rd18, [gather_u32_f64_param_5];
	ld.param.u64 	%rd19, [gather_u32_f64_param_6];
	ld.param.u64 	%rd20, [gather_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB33_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB33_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB33_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB33_5;

$L__BB33_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB33_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB33_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB33_8;

$L__BB33_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB33_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	shl.b64 	%rd32, %rd34, 3;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB33_2;

$L__BB33_9:
	ret;

}
	// .globl	gather_u32_u8
.visible .entry gather_u32_u8(
	.param .u64 gather_u32_u8_param_0,
	.param .u64 gather_u32_u8_param_1,
	.param .u64 gather_u32_u8_param_2,
	.param .u64 gather_u32_u8_param_3,
	.param .u64 gather_u32_u8_param_4,
	.param .u64 gather_u32_u8_param_5,
	.param .u64 gather_u32_u8_param_6,
	.param .u64 gather_u32_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd14, [gather_u32_u8_param_0];
	ld.param.u64 	%rd15, [gather_u32_u8_param_1];
	ld.param.u64 	%rd16, [gather_u32_u8_param_2];
	ld.param.u64 	%rd17, [gather_u32_u8_param_3];
	ld.param.u64 	%rd18, [gather_u32_u8_param_5];
	ld.param.u64 	%rd19, [gather_u32_u8_param_6];
	ld.param.u64 	%rd20, [gather_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd32, %r16;
	setp.ge.u64 	%p1, %rd32, %rd14;
	@%p1 bra 	$L__BB34_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB34_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB34_4;

	rem.u64 	%rd33, %rd32, %rd20;
	bra.uni 	$L__BB34_5;

$L__BB34_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd32;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd33, %r12;

$L__BB34_5:
	shl.b64 	%rd22, %rd32, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB34_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB34_8;

$L__BB34_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd32;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd34, %r15;

$L__BB34_8:
	mul.lo.s64 	%rd25, %rd34, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs1, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs1;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd32, %r16;
	setp.lt.u64 	%p4, %rd32, %rd14;
	@%p4 bra 	$L__BB34_2;

$L__BB34_9:
	ret;

}
	// .globl	gather_u32_i64
.visible .entry gather_u32_i64(
	.param .u64 gather_u32_i64_param_0,
	.param .u64 gather_u32_i64_param_1,
	.param .u64 gather_u32_i64_param_2,
	.param .u64 gather_u32_i64_param_3,
	.param .u64 gather_u32_i64_param_4,
	.param .u64 gather_u32_i64_param_5,
	.param .u64 gather_u32_i64_param_6,
	.param .u64 gather_u32_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd14, [gather_u32_i64_param_0];
	ld.param.u64 	%rd15, [gather_u32_i64_param_1];
	ld.param.u64 	%rd16, [gather_u32_i64_param_2];
	ld.param.u64 	%rd17, [gather_u32_i64_param_3];
	ld.param.u64 	%rd18, [gather_u32_i64_param_5];
	ld.param.u64 	%rd19, [gather_u32_i64_param_6];
	ld.param.u64 	%rd20, [gather_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r16, %r7, %r1, %r8;
	cvt.u64.u32 	%rd35, %r16;
	setp.ge.u64 	%p1, %rd35, %rd14;
	@%p1 bra 	$L__BB35_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB35_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB35_4;

	rem.u64 	%rd36, %rd35, %rd20;
	bra.uni 	$L__BB35_5;

$L__BB35_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd35;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd36, %r12;

$L__BB35_5:
	shl.b64 	%rd22, %rd35, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB35_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB35_8;

$L__BB35_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd35;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd37, %r15;

$L__BB35_8:
	mul.lo.s64 	%rd25, %rd37, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	shl.b64 	%rd33, %rd35, 3;
	add.s64 	%rd34, %rd5, %rd33;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd35, %r16;
	setp.lt.u64 	%p4, %rd35, %rd14;
	@%p4 bra 	$L__BB35_2;

$L__BB35_9:
	ret;

}
	// .globl	gather_u32_u32
.visible .entry gather_u32_u32(
	.param .u64 gather_u32_u32_param_0,
	.param .u64 gather_u32_u32_param_1,
	.param .u64 gather_u32_u32_param_2,
	.param .u64 gather_u32_u32_param_3,
	.param .u64 gather_u32_u32_param_4,
	.param .u64 gather_u32_u32_param_5,
	.param .u64 gather_u32_u32_param_6,
	.param .u64 gather_u32_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<18>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u32_u32_param_0];
	ld.param.u64 	%rd15, [gather_u32_u32_param_1];
	ld.param.u64 	%rd16, [gather_u32_u32_param_2];
	ld.param.u64 	%rd17, [gather_u32_u32_param_3];
	ld.param.u64 	%rd18, [gather_u32_u32_param_5];
	ld.param.u64 	%rd19, [gather_u32_u32_param_6];
	ld.param.u64 	%rd20, [gather_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r17, %r7, %r1, %r8;
	cvt.u64.u32 	%rd34, %r17;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB36_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r9, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r9;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB36_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB36_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB36_5;

$L__BB36_4:
	cvt.u32.u64 	%r10, %rd20;
	cvt.u32.u64 	%r11, %rd34;
	rem.u32 	%r12, %r11, %r10;
	cvt.u64.u32 	%rd35, %r12;

$L__BB36_5:
	shl.b64 	%rd22, %rd34, 2;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r5, [%rd23];
	and.b64  	%rd24, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd24, 0;
	@%p3 bra 	$L__BB36_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB36_8;

$L__BB36_7:
	cvt.u32.u64 	%r13, %rd2;
	cvt.u32.u64 	%r14, %rd34;
	div.u32 	%r15, %r14, %r13;
	cvt.u64.u32 	%rd36, %r15;

$L__BB36_8:
	mul.lo.s64 	%rd25, %rd36, %rd18;
	cvt.u64.u32 	%rd26, %r5;
	add.s64 	%rd27, %rd25, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r16, [%rd31];
	add.s64 	%rd33, %rd5, %rd22;
	st.global.u32 	[%rd33], %r16;
	add.s32 	%r17, %r17, %r3;
	cvt.u64.u32 	%rd34, %r17;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB36_2;

$L__BB36_9:
	ret;

}
	// .globl	gather_u8_f32
.visible .entry gather_u8_f32(
	.param .u64 gather_u8_f32_param_0,
	.param .u64 gather_u8_f32_param_1,
	.param .u64 gather_u8_f32_param_2,
	.param .u64 gather_u8_f32_param_3,
	.param .u64 gather_u8_f32_param_4,
	.param .u64 gather_u8_f32_param_5,
	.param .u64 gather_u8_f32_param_6,
	.param .u64 gather_u8_f32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f32_param_0];
	ld.param.u64 	%rd15, [gather_u8_f32_param_1];
	ld.param.u64 	%rd16, [gather_u8_f32_param_2];
	ld.param.u64 	%rd17, [gather_u8_f32_param_3];
	ld.param.u64 	%rd18, [gather_u8_f32_param_5];
	ld.param.u64 	%rd19, [gather_u8_f32_param_6];
	ld.param.u64 	%rd20, [gather_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB37_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB37_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB37_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB37_5;

$L__BB37_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB37_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB37_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB37_8;

$L__BB37_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB37_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f32 	%f1, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f32 	[%rd33], %f1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB37_2;

$L__BB37_9:
	ret;

}
	// .globl	gather_u8_f64
.visible .entry gather_u8_f64(
	.param .u64 gather_u8_f64_param_0,
	.param .u64 gather_u8_f64_param_1,
	.param .u64 gather_u8_f64_param_2,
	.param .u64 gather_u8_f64_param_3,
	.param .u64 gather_u8_f64_param_4,
	.param .u64 gather_u8_f64_param_5,
	.param .u64 gather_u8_f64_param_6,
	.param .u64 gather_u8_f64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .f64 	%fd<2>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_f64_param_0];
	ld.param.u64 	%rd15, [gather_u8_f64_param_1];
	ld.param.u64 	%rd16, [gather_u8_f64_param_2];
	ld.param.u64 	%rd17, [gather_u8_f64_param_3];
	ld.param.u64 	%rd18, [gather_u8_f64_param_5];
	ld.param.u64 	%rd19, [gather_u8_f64_param_6];
	ld.param.u64 	%rd20, [gather_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r15;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB38_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB38_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB38_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB38_5;

$L__BB38_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB38_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB38_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB38_8;

$L__BB38_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB38_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.f64 	%fd1, [%rd31];
	shl.b64 	%rd32, %rd34, 3;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.f64 	[%rd33], %fd1;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd34, %r15;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB38_2;

$L__BB38_9:
	ret;

}
	// .globl	gather_u8_u8
.visible .entry gather_u8_u8(
	.param .u64 gather_u8_u8_param_0,
	.param .u64 gather_u8_u8_param_1,
	.param .u64 gather_u8_u8_param_2,
	.param .u64 gather_u8_u8_param_3,
	.param .u64 gather_u8_u8_param_4,
	.param .u64 gather_u8_u8_param_5,
	.param .u64 gather_u8_u8_param_6,
	.param .u64 gather_u8_u8_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<35>;


	ld.param.u64 	%rd14, [gather_u8_u8_param_0];
	ld.param.u64 	%rd15, [gather_u8_u8_param_1];
	ld.param.u64 	%rd16, [gather_u8_u8_param_2];
	ld.param.u64 	%rd17, [gather_u8_u8_param_3];
	ld.param.u64 	%rd18, [gather_u8_u8_param_5];
	ld.param.u64 	%rd19, [gather_u8_u8_param_6];
	ld.param.u64 	%rd20, [gather_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd32, %r15;
	setp.ge.u64 	%p1, %rd32, %rd14;
	@%p1 bra 	$L__BB39_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB39_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB39_4;

	rem.u64 	%rd33, %rd32, %rd20;
	bra.uni 	$L__BB39_5;

$L__BB39_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd32;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd33, %r11;

$L__BB39_5:
	add.s64 	%rd22, %rd3, %rd32;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB39_7;

	div.u64 	%rd34, %rd32, %rd2;
	bra.uni 	$L__BB39_8;

$L__BB39_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd32;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd34, %r14;

$L__BB39_8:
	mul.lo.s64 	%rd24, %rd34, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd33;
	add.s64 	%rd30, %rd4, %rd29;
	ld.global.u8 	%rs2, [%rd30];
	add.s64 	%rd31, %rd5, %rd32;
	st.global.u8 	[%rd31], %rs2;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd32, %r15;
	setp.lt.u64 	%p4, %rd32, %rd14;
	@%p4 bra 	$L__BB39_2;

$L__BB39_9:
	ret;

}
	// .globl	gather_u8_u32
.visible .entry gather_u8_u32(
	.param .u64 gather_u8_u32_param_0,
	.param .u64 gather_u8_u32_param_1,
	.param .u64 gather_u8_u32_param_2,
	.param .u64 gather_u8_u32_param_3,
	.param .u64 gather_u8_u32_param_4,
	.param .u64 gather_u8_u32_param_5,
	.param .u64 gather_u8_u32_param_6,
	.param .u64 gather_u8_u32_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<17>;
	.reg .b64 	%rd<37>;


	ld.param.u64 	%rd14, [gather_u8_u32_param_0];
	ld.param.u64 	%rd15, [gather_u8_u32_param_1];
	ld.param.u64 	%rd16, [gather_u8_u32_param_2];
	ld.param.u64 	%rd17, [gather_u8_u32_param_3];
	ld.param.u64 	%rd18, [gather_u8_u32_param_5];
	ld.param.u64 	%rd19, [gather_u8_u32_param_6];
	ld.param.u64 	%rd20, [gather_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r16, %r6, %r1, %r7;
	cvt.u64.u32 	%rd34, %r16;
	setp.ge.u64 	%p1, %rd34, %rd14;
	@%p1 bra 	$L__BB40_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB40_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB40_4;

	rem.u64 	%rd35, %rd34, %rd20;
	bra.uni 	$L__BB40_5;

$L__BB40_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd34;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd35, %r11;

$L__BB40_5:
	add.s64 	%rd22, %rd3, %rd34;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB40_7;

	div.u64 	%rd36, %rd34, %rd2;
	bra.uni 	$L__BB40_8;

$L__BB40_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd34;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd36, %r14;

$L__BB40_8:
	mul.lo.s64 	%rd24, %rd36, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd35;
	shl.b64 	%rd30, %rd29, 2;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u32 	%r15, [%rd31];
	shl.b64 	%rd32, %rd34, 2;
	add.s64 	%rd33, %rd5, %rd32;
	st.global.u32 	[%rd33], %r15;
	add.s32 	%r16, %r16, %r3;
	cvt.u64.u32 	%rd34, %r16;
	setp.lt.u64 	%p4, %rd34, %rd14;
	@%p4 bra 	$L__BB40_2;

$L__BB40_9:
	ret;

}
	// .globl	gather_u8_i64
.visible .entry gather_u8_i64(
	.param .u64 gather_u8_i64_param_0,
	.param .u64 gather_u8_i64_param_1,
	.param .u64 gather_u8_i64_param_2,
	.param .u64 gather_u8_i64_param_3,
	.param .u64 gather_u8_i64_param_4,
	.param .u64 gather_u8_i64_param_5,
	.param .u64 gather_u8_i64_param_6,
	.param .u64 gather_u8_i64_param_7
)
{
	.reg .pred 	%p<5>;
	.reg .b16 	%rs<2>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd14, [gather_u8_i64_param_0];
	ld.param.u64 	%rd15, [gather_u8_i64_param_1];
	ld.param.u64 	%rd16, [gather_u8_i64_param_2];
	ld.param.u64 	%rd17, [gather_u8_i64_param_3];
	ld.param.u64 	%rd18, [gather_u8_i64_param_5];
	ld.param.u64 	%rd19, [gather_u8_i64_param_6];
	ld.param.u64 	%rd20, [gather_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r15, %r6, %r1, %r7;
	cvt.u64.u32 	%rd35, %r15;
	setp.ge.u64 	%p1, %rd35, %rd14;
	@%p1 bra 	$L__BB41_9;

	mul.lo.s64 	%rd2, %rd20, %rd19;
	mov.u32 	%r8, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r8;
	cvta.to.global.u64 	%rd3, %rd15;
	cvta.to.global.u64 	%rd4, %rd16;
	cvta.to.global.u64 	%rd5, %rd17;

$L__BB41_2:
	and.b64  	%rd21, %rd20, -4294967296;
	setp.eq.s64 	%p2, %rd21, 0;
	@%p2 bra 	$L__BB41_4;

	rem.u64 	%rd36, %rd35, %rd20;
	bra.uni 	$L__BB41_5;

$L__BB41_4:
	cvt.u32.u64 	%r9, %rd20;
	cvt.u32.u64 	%r10, %rd35;
	rem.u32 	%r11, %r10, %r9;
	cvt.u64.u32 	%rd36, %r11;

$L__BB41_5:
	add.s64 	%rd22, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd22];
	and.b64  	%rd23, %rd2, -4294967296;
	setp.eq.s64 	%p3, %rd23, 0;
	@%p3 bra 	$L__BB41_7;

	div.u64 	%rd37, %rd35, %rd2;
	bra.uni 	$L__BB41_8;

$L__BB41_7:
	cvt.u32.u64 	%r12, %rd2;
	cvt.u32.u64 	%r13, %rd35;
	div.u32 	%r14, %r13, %r12;
	cvt.u64.u32 	%rd37, %r14;

$L__BB41_8:
	mul.lo.s64 	%rd24, %rd37, %rd18;
	cvt.u64.u16 	%rd25, %rs1;
	and.b64  	%rd26, %rd25, 255;
	add.s64 	%rd27, %rd24, %rd26;
	mul.lo.s64 	%rd28, %rd27, %rd20;
	add.s64 	%rd29, %rd28, %rd36;
	shl.b64 	%rd30, %rd29, 3;
	add.s64 	%rd31, %rd4, %rd30;
	ld.global.u64 	%rd32, [%rd31];
	shl.b64 	%rd33, %rd35, 3;
	add.s64 	%rd34, %rd5, %rd33;
	st.global.u64 	[%rd34], %rd32;
	add.s32 	%r15, %r15, %r3;
	cvt.u64.u32 	%rd35, %r15;
	setp.lt.u64 	%p4, %rd35, %rd14;
	@%p4 bra 	$L__BB41_2;

$L__BB41_9:
	ret;

}
	// .globl	ia_i64_f32
.visible .entry ia_i64_f32(
	.param .u64 ia_i64_f32_param_0,
	.param .u64 ia_i64_f32_param_1,
	.param .u64 ia_i64_f32_param_2,
	.param .u64 ia_i64_f32_param_3,
	.param .u64 ia_i64_f32_param_4,
	.param .u64 ia_i64_f32_param_5,
	.param .u64 ia_i64_f32_param_6,
	.param .u64 ia_i64_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_f32_param_0];
	ld.param.u64 	%rd19, [ia_i64_f32_param_1];
	ld.param.u64 	%rd20, [ia_i64_f32_param_2];
	ld.param.u64 	%rd21, [ia_i64_f32_param_3];
	ld.param.u64 	%rd24, [ia_i64_f32_param_4];
	ld.param.u64 	%rd22, [ia_i64_f32_param_6];
	ld.param.u64 	%rd23, [ia_i64_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB42_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB42_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB42_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB42_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB42_6;

$L__BB42_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB42_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB42_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB42_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB42_3;
	bra.uni 	$L__BB42_10;

$L__BB42_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB42_9;

$L__BB42_10:
	ret;

}
	// .globl	ia_i64_f64
.visible .entry ia_i64_f64(
	.param .u64 ia_i64_f64_param_0,
	.param .u64 ia_i64_f64_param_1,
	.param .u64 ia_i64_f64_param_2,
	.param .u64 ia_i64_f64_param_3,
	.param .u64 ia_i64_f64_param_4,
	.param .u64 ia_i64_f64_param_5,
	.param .u64 ia_i64_f64_param_6,
	.param .u64 ia_i64_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_f64_param_0];
	ld.param.u64 	%rd19, [ia_i64_f64_param_1];
	ld.param.u64 	%rd20, [ia_i64_f64_param_2];
	ld.param.u64 	%rd21, [ia_i64_f64_param_3];
	ld.param.u64 	%rd24, [ia_i64_f64_param_4];
	ld.param.u64 	%rd22, [ia_i64_f64_param_6];
	ld.param.u64 	%rd23, [ia_i64_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB43_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB43_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB43_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB43_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB43_6;

$L__BB43_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB43_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB43_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB43_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB43_3;
	bra.uni 	$L__BB43_10;

$L__BB43_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB43_9;

$L__BB43_10:
	ret;

}
	// .globl	ia_i64_u8
.visible .entry ia_i64_u8(
	.param .u64 ia_i64_u8_param_0,
	.param .u64 ia_i64_u8_param_1,
	.param .u64 ia_i64_u8_param_2,
	.param .u64 ia_i64_u8_param_3,
	.param .u64 ia_i64_u8_param_4,
	.param .u64 ia_i64_u8_param_5,
	.param .u64 ia_i64_u8_param_6,
	.param .u64 ia_i64_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [ia_i64_u8_param_0];
	ld.param.u64 	%rd19, [ia_i64_u8_param_1];
	ld.param.u64 	%rd20, [ia_i64_u8_param_2];
	ld.param.u64 	%rd21, [ia_i64_u8_param_3];
	ld.param.u64 	%rd24, [ia_i64_u8_param_4];
	ld.param.u64 	%rd22, [ia_i64_u8_param_6];
	ld.param.u64 	%rd23, [ia_i64_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB44_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB44_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB44_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB44_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB44_6;

$L__BB44_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB44_6:
	mul.lo.s64 	%rd13, %rd41, %rd19;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB44_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd43, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd19;
	@%p4 bra 	$L__BB44_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB44_3;
	bra.uni 	$L__BB44_10;

$L__BB44_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB44_9;

$L__BB44_10:
	ret;

}
	// .globl	ia_i64_i64
.visible .entry ia_i64_i64(
	.param .u64 ia_i64_i64_param_0,
	.param .u64 ia_i64_i64_param_1,
	.param .u64 ia_i64_i64_param_2,
	.param .u64 ia_i64_i64_param_3,
	.param .u64 ia_i64_i64_param_4,
	.param .u64 ia_i64_i64_param_5,
	.param .u64 ia_i64_i64_param_6,
	.param .u64 ia_i64_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [ia_i64_i64_param_0];
	ld.param.u64 	%rd19, [ia_i64_i64_param_1];
	ld.param.u64 	%rd20, [ia_i64_i64_param_2];
	ld.param.u64 	%rd21, [ia_i64_i64_param_3];
	ld.param.u64 	%rd24, [ia_i64_i64_param_4];
	ld.param.u64 	%rd22, [ia_i64_i64_param_6];
	ld.param.u64 	%rd23, [ia_i64_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB45_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB45_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB45_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB45_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB45_6;

$L__BB45_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB45_6:
	mul.lo.s64 	%rd13, %rd46, %rd19;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB45_7:
	add.s64 	%rd28, %rd48, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd47;
	shl.b64 	%rd31, %rd48, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd19;
	@%p4 bra 	$L__BB45_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB45_3;
	bra.uni 	$L__BB45_10;

$L__BB45_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB45_9;

$L__BB45_10:
	ret;

}
	// .globl	ia_i64_u32
.visible .entry ia_i64_u32(
	.param .u64 ia_i64_u32_param_0,
	.param .u64 ia_i64_u32_param_1,
	.param .u64 ia_i64_u32_param_2,
	.param .u64 ia_i64_u32_param_3,
	.param .u64 ia_i64_u32_param_4,
	.param .u64 ia_i64_u32_param_5,
	.param .u64 ia_i64_u32_param_6,
	.param .u64 ia_i64_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_i64_u32_param_0];
	ld.param.u64 	%rd19, [ia_i64_u32_param_1];
	ld.param.u64 	%rd20, [ia_i64_u32_param_2];
	ld.param.u64 	%rd21, [ia_i64_u32_param_3];
	ld.param.u64 	%rd24, [ia_i64_u32_param_4];
	ld.param.u64 	%rd22, [ia_i64_u32_param_6];
	ld.param.u64 	%rd23, [ia_i64_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB46_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB46_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB46_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB46_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB46_6;

$L__BB46_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB46_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB46_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd45, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB46_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB46_3;
	bra.uni 	$L__BB46_10;

$L__BB46_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB46_9;

$L__BB46_10:
	ret;

}
	// .globl	ia_u32_f32
.visible .entry ia_u32_f32(
	.param .u64 ia_u32_f32_param_0,
	.param .u64 ia_u32_f32_param_1,
	.param .u64 ia_u32_f32_param_2,
	.param .u64 ia_u32_f32_param_3,
	.param .u64 ia_u32_f32_param_4,
	.param .u64 ia_u32_f32_param_5,
	.param .u64 ia_u32_f32_param_6,
	.param .u64 ia_u32_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f32_param_0];
	ld.param.u64 	%rd19, [ia_u32_f32_param_1];
	ld.param.u64 	%rd20, [ia_u32_f32_param_2];
	ld.param.u64 	%rd21, [ia_u32_f32_param_3];
	ld.param.u64 	%rd24, [ia_u32_f32_param_4];
	ld.param.u64 	%rd22, [ia_u32_f32_param_6];
	ld.param.u64 	%rd23, [ia_u32_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB47_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB47_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB47_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB47_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB47_6;

$L__BB47_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB47_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB47_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB47_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB47_3;
	bra.uni 	$L__BB47_10;

$L__BB47_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB47_9;

$L__BB47_10:
	ret;

}
	// .globl	ia_u32_f64
.visible .entry ia_u32_f64(
	.param .u64 ia_u32_f64_param_0,
	.param .u64 ia_u32_f64_param_1,
	.param .u64 ia_u32_f64_param_2,
	.param .u64 ia_u32_f64_param_3,
	.param .u64 ia_u32_f64_param_4,
	.param .u64 ia_u32_f64_param_5,
	.param .u64 ia_u32_f64_param_6,
	.param .u64 ia_u32_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_f64_param_0];
	ld.param.u64 	%rd19, [ia_u32_f64_param_1];
	ld.param.u64 	%rd20, [ia_u32_f64_param_2];
	ld.param.u64 	%rd21, [ia_u32_f64_param_3];
	ld.param.u64 	%rd24, [ia_u32_f64_param_4];
	ld.param.u64 	%rd22, [ia_u32_f64_param_6];
	ld.param.u64 	%rd23, [ia_u32_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB48_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB48_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB48_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB48_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB48_6;

$L__BB48_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB48_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB48_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB48_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB48_3;
	bra.uni 	$L__BB48_10;

$L__BB48_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB48_9;

$L__BB48_10:
	ret;

}
	// .globl	ia_u32_u8
.visible .entry ia_u32_u8(
	.param .u64 ia_u32_u8_param_0,
	.param .u64 ia_u32_u8_param_1,
	.param .u64 ia_u32_u8_param_2,
	.param .u64 ia_u32_u8_param_3,
	.param .u64 ia_u32_u8_param_4,
	.param .u64 ia_u32_u8_param_5,
	.param .u64 ia_u32_u8_param_6,
	.param .u64 ia_u32_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [ia_u32_u8_param_0];
	ld.param.u64 	%rd19, [ia_u32_u8_param_1];
	ld.param.u64 	%rd20, [ia_u32_u8_param_2];
	ld.param.u64 	%rd21, [ia_u32_u8_param_3];
	ld.param.u64 	%rd24, [ia_u32_u8_param_4];
	ld.param.u64 	%rd22, [ia_u32_u8_param_6];
	ld.param.u64 	%rd23, [ia_u32_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB49_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB49_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB49_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB49_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB49_6;

$L__BB49_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB49_6:
	mul.lo.s64 	%rd13, %rd41, %rd19;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB49_7:
	shl.b64 	%rd28, %rd43, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd43, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd42;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd33;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd19;
	@%p4 bra 	$L__BB49_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB49_3;
	bra.uni 	$L__BB49_10;

$L__BB49_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB49_9;

$L__BB49_10:
	ret;

}
	// .globl	ia_u32_i64
.visible .entry ia_u32_i64(
	.param .u64 ia_u32_i64_param_0,
	.param .u64 ia_u32_i64_param_1,
	.param .u64 ia_u32_i64_param_2,
	.param .u64 ia_u32_i64_param_3,
	.param .u64 ia_u32_i64_param_4,
	.param .u64 ia_u32_i64_param_5,
	.param .u64 ia_u32_i64_param_6,
	.param .u64 ia_u32_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [ia_u32_i64_param_0];
	ld.param.u64 	%rd19, [ia_u32_i64_param_1];
	ld.param.u64 	%rd20, [ia_u32_i64_param_2];
	ld.param.u64 	%rd21, [ia_u32_i64_param_3];
	ld.param.u64 	%rd24, [ia_u32_i64_param_4];
	ld.param.u64 	%rd22, [ia_u32_i64_param_6];
	ld.param.u64 	%rd23, [ia_u32_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB50_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB50_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB50_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB50_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB50_6;

$L__BB50_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB50_6:
	mul.lo.s64 	%rd13, %rd46, %rd19;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB50_7:
	shl.b64 	%rd28, %rd48, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd48, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd47;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd33, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd19;
	@%p4 bra 	$L__BB50_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB50_3;
	bra.uni 	$L__BB50_10;

$L__BB50_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB50_9;

$L__BB50_10:
	ret;

}
	// .globl	ia_u32_u32
.visible .entry ia_u32_u32(
	.param .u64 ia_u32_u32_param_0,
	.param .u64 ia_u32_u32_param_1,
	.param .u64 ia_u32_u32_param_2,
	.param .u64 ia_u32_u32_param_3,
	.param .u64 ia_u32_u32_param_4,
	.param .u64 ia_u32_u32_param_5,
	.param .u64 ia_u32_u32_param_6,
	.param .u64 ia_u32_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [ia_u32_u32_param_0];
	ld.param.u64 	%rd19, [ia_u32_u32_param_1];
	ld.param.u64 	%rd20, [ia_u32_u32_param_2];
	ld.param.u64 	%rd21, [ia_u32_u32_param_3];
	ld.param.u64 	%rd24, [ia_u32_u32_param_4];
	ld.param.u64 	%rd22, [ia_u32_u32_param_6];
	ld.param.u64 	%rd23, [ia_u32_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB51_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB51_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB51_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB51_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB51_6;

$L__BB51_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB51_6:
	mul.lo.s64 	%rd13, %rd43, %rd19;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB51_7:
	shl.b64 	%rd28, %rd45, 2;
	add.s64 	%rd29, %rd5, %rd28;
	ld.global.u32 	%rd30, [%rd29];
	add.s64 	%rd31, %rd45, %rd13;
	mul.lo.s64 	%rd32, %rd31, %rd23;
	add.s64 	%rd33, %rd32, %rd44;
	add.s64 	%rd34, %rd14, %rd30;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd33, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd19;
	@%p4 bra 	$L__BB51_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB51_3;
	bra.uni 	$L__BB51_10;

$L__BB51_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB51_9;

$L__BB51_10:
	ret;

}
	// .globl	ia_u8_f32
.visible .entry ia_u8_f32(
	.param .u64 ia_u8_f32_param_0,
	.param .u64 ia_u8_f32_param_1,
	.param .u64 ia_u8_f32_param_2,
	.param .u64 ia_u8_f32_param_3,
	.param .u64 ia_u8_f32_param_4,
	.param .u64 ia_u8_f32_param_5,
	.param .u64 ia_u8_f32_param_6,
	.param .u64 ia_u8_f32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f32_param_0];
	ld.param.u64 	%rd19, [ia_u8_f32_param_1];
	ld.param.u64 	%rd20, [ia_u8_f32_param_2];
	ld.param.u64 	%rd21, [ia_u8_f32_param_3];
	ld.param.u64 	%rd24, [ia_u8_f32_param_4];
	ld.param.u64 	%rd22, [ia_u8_f32_param_6];
	ld.param.u64 	%rd23, [ia_u8_f32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB52_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB52_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB52_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB52_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB52_6;

$L__BB52_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB52_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB52_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB52_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB52_3;
	bra.uni 	$L__BB52_10;

$L__BB52_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB52_9;

$L__BB52_10:
	ret;

}
	// .globl	ia_u8_f64
.visible .entry ia_u8_f64(
	.param .u64 ia_u8_f64_param_0,
	.param .u64 ia_u8_f64_param_1,
	.param .u64 ia_u8_f64_param_2,
	.param .u64 ia_u8_f64_param_3,
	.param .u64 ia_u8_f64_param_4,
	.param .u64 ia_u8_f64_param_5,
	.param .u64 ia_u8_f64_param_6,
	.param .u64 ia_u8_f64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_f64_param_0];
	ld.param.u64 	%rd19, [ia_u8_f64_param_1];
	ld.param.u64 	%rd20, [ia_u8_f64_param_2];
	ld.param.u64 	%rd21, [ia_u8_f64_param_3];
	ld.param.u64 	%rd24, [ia_u8_f64_param_4];
	ld.param.u64 	%rd22, [ia_u8_f64_param_6];
	ld.param.u64 	%rd23, [ia_u8_f64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB53_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB53_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB53_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB53_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB53_6;

$L__BB53_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB53_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB53_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB53_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB53_3;
	bra.uni 	$L__BB53_10;

$L__BB53_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB53_9;

$L__BB53_10:
	ret;

}
	// .globl	ia_u8_u8
.visible .entry ia_u8_u8(
	.param .u64 ia_u8_u8_param_0,
	.param .u64 ia_u8_u8_param_1,
	.param .u64 ia_u8_u8_param_2,
	.param .u64 ia_u8_u8_param_3,
	.param .u64 ia_u8_u8_param_4,
	.param .u64 ia_u8_u8_param_5,
	.param .u64 ia_u8_u8_param_6,
	.param .u64 ia_u8_u8_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd18, [ia_u8_u8_param_0];
	ld.param.u64 	%rd19, [ia_u8_u8_param_1];
	ld.param.u64 	%rd20, [ia_u8_u8_param_2];
	ld.param.u64 	%rd21, [ia_u8_u8_param_3];
	ld.param.u64 	%rd24, [ia_u8_u8_param_4];
	ld.param.u64 	%rd22, [ia_u8_u8_param_6];
	ld.param.u64 	%rd23, [ia_u8_u8_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd39, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd39;
	@%p1 bra 	$L__BB54_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB54_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB54_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB54_5;

	div.u64 	%rd40, %rd39, %rd23;
	mul.lo.s64 	%rd26, %rd40, %rd23;
	sub.s64 	%rd41, %rd39, %rd26;
	bra.uni 	$L__BB54_6;

$L__BB54_5:
	cvt.u32.u64 	%r14, %rd39;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd40, %r15;
	cvt.u64.u32 	%rd41, %r17;

$L__BB54_6:
	mul.lo.s64 	%rd13, %rd40, %rd19;
	mul.lo.s64 	%rd14, %rd40, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd42, 0;

$L__BB54_7:
	add.s64 	%rd28, %rd5, %rd42;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd42, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd41;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd41;
	add.s64 	%rd36, %rd4, %rd32;
	add.s64 	%rd37, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd37];
	ld.global.u8 	%rs2, [%rd36];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd37], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd42, %r20;
	setp.lt.u64 	%p4, %rd42, %rd19;
	@%p4 bra 	$L__BB54_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p5, %rd2, %rd39;
	@%p5 bra 	$L__BB54_3;
	bra.uni 	$L__BB54_10;

$L__BB54_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd38, %r19;
	setp.gt.u64 	%p6, %rd2, %rd38;
	@%p6 bra 	$L__BB54_9;

$L__BB54_10:
	ret;

}
	// .globl	ia_u8_u32
.visible .entry ia_u8_u32(
	.param .u64 ia_u8_u32_param_0,
	.param .u64 ia_u8_u32_param_1,
	.param .u64 ia_u8_u32_param_2,
	.param .u64 ia_u8_u32_param_3,
	.param .u64 ia_u8_u32_param_4,
	.param .u64 ia_u8_u32_param_5,
	.param .u64 ia_u8_u32_param_6,
	.param .u64 ia_u8_u32_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [ia_u8_u32_param_0];
	ld.param.u64 	%rd19, [ia_u8_u32_param_1];
	ld.param.u64 	%rd20, [ia_u8_u32_param_2];
	ld.param.u64 	%rd21, [ia_u8_u32_param_3];
	ld.param.u64 	%rd24, [ia_u8_u32_param_4];
	ld.param.u64 	%rd22, [ia_u8_u32_param_6];
	ld.param.u64 	%rd23, [ia_u8_u32_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB55_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB55_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB55_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB55_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB55_6;

$L__BB55_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB55_6:
	mul.lo.s64 	%rd13, %rd42, %rd19;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB55_7:
	add.s64 	%rd28, %rd5, %rd44;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd44, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd43;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd32, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd19;
	@%p4 bra 	$L__BB55_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB55_3;
	bra.uni 	$L__BB55_10;

$L__BB55_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB55_9;

$L__BB55_10:
	ret;

}
	// .globl	ia_u8_i64
.visible .entry ia_u8_i64(
	.param .u64 ia_u8_i64_param_0,
	.param .u64 ia_u8_i64_param_1,
	.param .u64 ia_u8_i64_param_2,
	.param .u64 ia_u8_i64_param_3,
	.param .u64 ia_u8_i64_param_4,
	.param .u64 ia_u8_i64_param_5,
	.param .u64 ia_u8_i64_param_6,
	.param .u64 ia_u8_i64_param_7
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [ia_u8_i64_param_0];
	ld.param.u64 	%rd19, [ia_u8_i64_param_1];
	ld.param.u64 	%rd20, [ia_u8_i64_param_2];
	ld.param.u64 	%rd21, [ia_u8_i64_param_3];
	ld.param.u64 	%rd24, [ia_u8_i64_param_4];
	ld.param.u64 	%rd22, [ia_u8_i64_param_6];
	ld.param.u64 	%rd23, [ia_u8_i64_param_7];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB56_10;

	setp.eq.s64 	%p2, %rd19, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB56_9;

	cvta.to.global.u64 	%rd3, %rd21;
	cvta.to.global.u64 	%rd4, %rd20;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB56_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB56_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB56_6;

$L__BB56_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB56_6:
	mul.lo.s64 	%rd13, %rd45, %rd19;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB56_7:
	add.s64 	%rd28, %rd5, %rd47;
	ld.global.u8 	%rd29, [%rd28];
	add.s64 	%rd30, %rd47, %rd13;
	mul.lo.s64 	%rd31, %rd30, %rd23;
	add.s64 	%rd32, %rd31, %rd46;
	add.s64 	%rd33, %rd14, %rd29;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd46;
	shl.b64 	%rd36, %rd32, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd19;
	@%p4 bra 	$L__BB56_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB56_3;
	bra.uni 	$L__BB56_10;

$L__BB56_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB56_9;

$L__BB56_10:
	ret;

}
	// .globl	sa_i64_f32
.visible .entry sa_i64_f32(
	.param .u64 sa_i64_f32_param_0,
	.param .u64 sa_i64_f32_param_1,
	.param .u64 sa_i64_f32_param_2,
	.param .u64 sa_i64_f32_param_3,
	.param .u64 sa_i64_f32_param_4,
	.param .u64 sa_i64_f32_param_5,
	.param .u64 sa_i64_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_i64_f32_param_0];
	ld.param.u64 	%rd19, [sa_i64_f32_param_1];
	ld.param.u64 	%rd20, [sa_i64_f32_param_2];
	ld.param.u64 	%rd24, [sa_i64_f32_param_3];
	ld.param.u64 	%rd21, [sa_i64_f32_param_4];
	ld.param.u64 	%rd22, [sa_i64_f32_param_5];
	ld.param.u64 	%rd23, [sa_i64_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB57_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB57_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB57_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB57_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB57_6;

$L__BB57_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB57_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB57_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f32 	%f1, [%rd40];
	ld.global.f32 	%f2, [%rd38];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd40], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB57_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB57_3;
	bra.uni 	$L__BB57_10;

$L__BB57_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB57_9;

$L__BB57_10:
	ret;

}
	// .globl	sa_i64_f64
.visible .entry sa_i64_f64(
	.param .u64 sa_i64_f64_param_0,
	.param .u64 sa_i64_f64_param_1,
	.param .u64 sa_i64_f64_param_2,
	.param .u64 sa_i64_f64_param_3,
	.param .u64 sa_i64_f64_param_4,
	.param .u64 sa_i64_f64_param_5,
	.param .u64 sa_i64_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_i64_f64_param_0];
	ld.param.u64 	%rd19, [sa_i64_f64_param_1];
	ld.param.u64 	%rd20, [sa_i64_f64_param_2];
	ld.param.u64 	%rd24, [sa_i64_f64_param_3];
	ld.param.u64 	%rd21, [sa_i64_f64_param_4];
	ld.param.u64 	%rd22, [sa_i64_f64_param_5];
	ld.param.u64 	%rd23, [sa_i64_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB58_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB58_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB58_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB58_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB58_6;

$L__BB58_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB58_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB58_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB58_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB58_3;
	bra.uni 	$L__BB58_10;

$L__BB58_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB58_9;

$L__BB58_10:
	ret;

}
	// .globl	sa_i64_u8
.visible .entry sa_i64_u8(
	.param .u64 sa_i64_u8_param_0,
	.param .u64 sa_i64_u8_param_1,
	.param .u64 sa_i64_u8_param_2,
	.param .u64 sa_i64_u8_param_3,
	.param .u64 sa_i64_u8_param_4,
	.param .u64 sa_i64_u8_param_5,
	.param .u64 sa_i64_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [sa_i64_u8_param_0];
	ld.param.u64 	%rd19, [sa_i64_u8_param_1];
	ld.param.u64 	%rd20, [sa_i64_u8_param_2];
	ld.param.u64 	%rd24, [sa_i64_u8_param_3];
	ld.param.u64 	%rd21, [sa_i64_u8_param_4];
	ld.param.u64 	%rd22, [sa_i64_u8_param_5];
	ld.param.u64 	%rd23, [sa_i64_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB59_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB59_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB59_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB59_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB59_6;

$L__BB59_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB59_6:
	mul.lo.s64 	%rd13, %rd41, %rd21;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB59_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd21;
	@%p4 bra 	$L__BB59_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB59_3;
	bra.uni 	$L__BB59_10;

$L__BB59_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB59_9;

$L__BB59_10:
	ret;

}
	// .globl	sa_i64_i64
.visible .entry sa_i64_i64(
	.param .u64 sa_i64_i64_param_0,
	.param .u64 sa_i64_i64_param_1,
	.param .u64 sa_i64_i64_param_2,
	.param .u64 sa_i64_i64_param_3,
	.param .u64 sa_i64_i64_param_4,
	.param .u64 sa_i64_i64_param_5,
	.param .u64 sa_i64_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [sa_i64_i64_param_0];
	ld.param.u64 	%rd19, [sa_i64_i64_param_1];
	ld.param.u64 	%rd20, [sa_i64_i64_param_2];
	ld.param.u64 	%rd24, [sa_i64_i64_param_3];
	ld.param.u64 	%rd21, [sa_i64_i64_param_4];
	ld.param.u64 	%rd22, [sa_i64_i64_param_5];
	ld.param.u64 	%rd23, [sa_i64_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB60_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB60_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB60_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB60_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB60_6;

$L__BB60_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB60_6:
	mul.lo.s64 	%rd13, %rd45, %rd21;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB60_7:
	add.s64 	%rd28, %rd47, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd46;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd46;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd21;
	@%p4 bra 	$L__BB60_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB60_3;
	bra.uni 	$L__BB60_10;

$L__BB60_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB60_9;

$L__BB60_10:
	ret;

}
	// .globl	sa_i64_u32
.visible .entry sa_i64_u32(
	.param .u64 sa_i64_u32_param_0,
	.param .u64 sa_i64_u32_param_1,
	.param .u64 sa_i64_u32_param_2,
	.param .u64 sa_i64_u32_param_3,
	.param .u64 sa_i64_u32_param_4,
	.param .u64 sa_i64_u32_param_5,
	.param .u64 sa_i64_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_i64_u32_param_0];
	ld.param.u64 	%rd19, [sa_i64_u32_param_1];
	ld.param.u64 	%rd20, [sa_i64_u32_param_2];
	ld.param.u64 	%rd24, [sa_i64_u32_param_3];
	ld.param.u64 	%rd21, [sa_i64_u32_param_4];
	ld.param.u64 	%rd22, [sa_i64_u32_param_5];
	ld.param.u64 	%rd23, [sa_i64_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB61_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB61_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB61_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB61_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB61_6;

$L__BB61_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB61_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd45, 0;

$L__BB61_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 3;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u64 	%rd33, [%rd32];
	add.s64 	%rd34, %rd33, %rd14;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 2;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 2;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u32 	%r19, [%rd40];
	ld.global.u32 	%r20, [%rd38];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd40], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd45, %r23;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB61_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd42, %r22;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB61_3;
	bra.uni 	$L__BB61_10;

$L__BB61_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB61_9;

$L__BB61_10:
	ret;

}
	// .globl	sa_u32_f32
.visible .entry sa_u32_f32(
	.param .u64 sa_u32_f32_param_0,
	.param .u64 sa_u32_f32_param_1,
	.param .u64 sa_u32_f32_param_2,
	.param .u64 sa_u32_f32_param_3,
	.param .u64 sa_u32_f32_param_4,
	.param .u64 sa_u32_f32_param_5,
	.param .u64 sa_u32_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u32_f32_param_0];
	ld.param.u64 	%rd19, [sa_u32_f32_param_1];
	ld.param.u64 	%rd20, [sa_u32_f32_param_2];
	ld.param.u64 	%rd24, [sa_u32_f32_param_3];
	ld.param.u64 	%rd21, [sa_u32_f32_param_4];
	ld.param.u64 	%rd22, [sa_u32_f32_param_5];
	ld.param.u64 	%rd23, [sa_u32_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB62_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB62_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB62_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB62_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB62_6;

$L__BB62_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB62_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB62_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB62_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB62_3;
	bra.uni 	$L__BB62_10;

$L__BB62_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB62_9;

$L__BB62_10:
	ret;

}
	// .globl	sa_u32_f64
.visible .entry sa_u32_f64(
	.param .u64 sa_u32_f64_param_0,
	.param .u64 sa_u32_f64_param_1,
	.param .u64 sa_u32_f64_param_2,
	.param .u64 sa_u32_f64_param_3,
	.param .u64 sa_u32_f64_param_4,
	.param .u64 sa_u32_f64_param_5,
	.param .u64 sa_u32_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<46>;


	ld.param.u64 	%rd18, [sa_u32_f64_param_0];
	ld.param.u64 	%rd19, [sa_u32_f64_param_1];
	ld.param.u64 	%rd20, [sa_u32_f64_param_2];
	ld.param.u64 	%rd24, [sa_u32_f64_param_3];
	ld.param.u64 	%rd21, [sa_u32_f64_param_4];
	ld.param.u64 	%rd22, [sa_u32_f64_param_5];
	ld.param.u64 	%rd23, [sa_u32_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd42, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd42;
	@%p1 bra 	$L__BB63_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB63_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB63_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB63_5;

	div.u64 	%rd43, %rd42, %rd23;
	mul.lo.s64 	%rd26, %rd43, %rd23;
	sub.s64 	%rd44, %rd42, %rd26;
	bra.uni 	$L__BB63_6;

$L__BB63_5:
	cvt.u32.u64 	%r14, %rd42;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd43, %r15;
	cvt.u64.u32 	%rd44, %r17;

$L__BB63_6:
	mul.lo.s64 	%rd13, %rd43, %rd21;
	mul.lo.s64 	%rd14, %rd43, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd45, 0;

$L__BB63_7:
	add.s64 	%rd28, %rd45, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd44;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd44;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.f64 	%fd1, [%rd40];
	ld.global.f64 	%fd2, [%rd38];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd40], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd45, %r20;
	setp.lt.u64 	%p4, %rd45, %rd21;
	@%p4 bra 	$L__BB63_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd42, %r19;
	setp.gt.u64 	%p5, %rd2, %rd42;
	@%p5 bra 	$L__BB63_3;
	bra.uni 	$L__BB63_10;

$L__BB63_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p6, %rd2, %rd41;
	@%p6 bra 	$L__BB63_9;

$L__BB63_10:
	ret;

}
	// .globl	sa_u32_u8
.visible .entry sa_u32_u8(
	.param .u64 sa_u32_u8_param_0,
	.param .u64 sa_u32_u8_param_1,
	.param .u64 sa_u32_u8_param_2,
	.param .u64 sa_u32_u8_param_3,
	.param .u64 sa_u32_u8_param_4,
	.param .u64 sa_u32_u8_param_5,
	.param .u64 sa_u32_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<44>;


	ld.param.u64 	%rd18, [sa_u32_u8_param_0];
	ld.param.u64 	%rd19, [sa_u32_u8_param_1];
	ld.param.u64 	%rd20, [sa_u32_u8_param_2];
	ld.param.u64 	%rd24, [sa_u32_u8_param_3];
	ld.param.u64 	%rd21, [sa_u32_u8_param_4];
	ld.param.u64 	%rd22, [sa_u32_u8_param_5];
	ld.param.u64 	%rd23, [sa_u32_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd40, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd40;
	@%p1 bra 	$L__BB64_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB64_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB64_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB64_5;

	div.u64 	%rd41, %rd40, %rd23;
	mul.lo.s64 	%rd26, %rd41, %rd23;
	sub.s64 	%rd42, %rd40, %rd26;
	bra.uni 	$L__BB64_6;

$L__BB64_5:
	cvt.u32.u64 	%r14, %rd40;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd41, %r15;
	cvt.u64.u32 	%rd42, %r17;

$L__BB64_6:
	mul.lo.s64 	%rd13, %rd41, %rd21;
	mul.lo.s64 	%rd14, %rd41, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd43, 0;

$L__BB64_7:
	add.s64 	%rd28, %rd43, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd42;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd42;
	add.s64 	%rd37, %rd4, %rd30;
	add.s64 	%rd38, %rd3, %rd36;
	ld.global.u8 	%rs1, [%rd38];
	ld.global.u8 	%rs2, [%rd37];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd38], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd43, %r20;
	setp.lt.u64 	%p4, %rd43, %rd21;
	@%p4 bra 	$L__BB64_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p5, %rd2, %rd40;
	@%p5 bra 	$L__BB64_3;
	bra.uni 	$L__BB64_10;

$L__BB64_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p6, %rd2, %rd39;
	@%p6 bra 	$L__BB64_9;

$L__BB64_10:
	ret;

}
	// .globl	sa_u32_i64
.visible .entry sa_u32_i64(
	.param .u64 sa_u32_i64_param_0,
	.param .u64 sa_u32_i64_param_1,
	.param .u64 sa_u32_i64_param_2,
	.param .u64 sa_u32_i64_param_3,
	.param .u64 sa_u32_i64_param_4,
	.param .u64 sa_u32_i64_param_5,
	.param .u64 sa_u32_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<49>;


	ld.param.u64 	%rd18, [sa_u32_i64_param_0];
	ld.param.u64 	%rd19, [sa_u32_i64_param_1];
	ld.param.u64 	%rd20, [sa_u32_i64_param_2];
	ld.param.u64 	%rd24, [sa_u32_i64_param_3];
	ld.param.u64 	%rd21, [sa_u32_i64_param_4];
	ld.param.u64 	%rd22, [sa_u32_i64_param_5];
	ld.param.u64 	%rd23, [sa_u32_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd45, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd45;
	@%p1 bra 	$L__BB65_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB65_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB65_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB65_5;

	div.u64 	%rd46, %rd45, %rd23;
	mul.lo.s64 	%rd26, %rd46, %rd23;
	sub.s64 	%rd47, %rd45, %rd26;
	bra.uni 	$L__BB65_6;

$L__BB65_5:
	cvt.u32.u64 	%r14, %rd45;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd46, %r15;
	cvt.u64.u32 	%rd47, %r17;

$L__BB65_6:
	mul.lo.s64 	%rd13, %rd46, %rd21;
	mul.lo.s64 	%rd14, %rd46, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd48, 0;

$L__BB65_7:
	add.s64 	%rd28, %rd48, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd47;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd47;
	shl.b64 	%rd37, %rd30, 3;
	add.s64 	%rd38, %rd4, %rd37;
	shl.b64 	%rd39, %rd36, 3;
	add.s64 	%rd40, %rd3, %rd39;
	ld.global.u64 	%rd41, [%rd40];
	ld.global.u64 	%rd42, [%rd38];
	add.s64 	%rd43, %rd41, %rd42;
	st.global.u64 	[%rd40], %rd43;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd48, %r20;
	setp.lt.u64 	%p4, %rd48, %rd21;
	@%p4 bra 	$L__BB65_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd45, %r19;
	setp.gt.u64 	%p5, %rd2, %rd45;
	@%p5 bra 	$L__BB65_3;
	bra.uni 	$L__BB65_10;

$L__BB65_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p6, %rd2, %rd44;
	@%p6 bra 	$L__BB65_9;

$L__BB65_10:
	ret;

}
	// .globl	sa_u32_u32
.visible .entry sa_u32_u32(
	.param .u64 sa_u32_u32_param_0,
	.param .u64 sa_u32_u32_param_1,
	.param .u64 sa_u32_u32_param_2,
	.param .u64 sa_u32_u32_param_3,
	.param .u64 sa_u32_u32_param_4,
	.param .u64 sa_u32_u32_param_5,
	.param .u64 sa_u32_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u32_u32_param_0];
	ld.param.u64 	%rd19, [sa_u32_u32_param_1];
	ld.param.u64 	%rd20, [sa_u32_u32_param_2];
	ld.param.u64 	%rd24, [sa_u32_u32_param_3];
	ld.param.u64 	%rd21, [sa_u32_u32_param_4];
	ld.param.u64 	%rd22, [sa_u32_u32_param_5];
	ld.param.u64 	%rd23, [sa_u32_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB66_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB66_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB66_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB66_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB66_6;

$L__BB66_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB66_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB66_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd5, %rd31;
	ld.global.u32 	%rd33, [%rd32];
	add.s64 	%rd34, %rd14, %rd33;
	mul.lo.s64 	%rd35, %rd34, %rd23;
	add.s64 	%rd36, %rd35, %rd43;
	add.s64 	%rd37, %rd4, %rd31;
	shl.b64 	%rd38, %rd36, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB66_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB66_3;
	bra.uni 	$L__BB66_10;

$L__BB66_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB66_9;

$L__BB66_10:
	ret;

}
	// .globl	sa_u8_f32
.visible .entry sa_u8_f32(
	.param .u64 sa_u8_f32_param_0,
	.param .u64 sa_u8_f32_param_1,
	.param .u64 sa_u8_f32_param_2,
	.param .u64 sa_u8_f32_param_3,
	.param .u64 sa_u8_f32_param_4,
	.param .u64 sa_u8_f32_param_5,
	.param .u64 sa_u8_f32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .f32 	%f<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f32_param_0];
	ld.param.u64 	%rd19, [sa_u8_f32_param_1];
	ld.param.u64 	%rd20, [sa_u8_f32_param_2];
	ld.param.u64 	%rd24, [sa_u8_f32_param_3];
	ld.param.u64 	%rd21, [sa_u8_f32_param_4];
	ld.param.u64 	%rd22, [sa_u8_f32_param_5];
	ld.param.u64 	%rd23, [sa_u8_f32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB67_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB67_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB67_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB67_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB67_6;

$L__BB67_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB67_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB67_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f32 	%f1, [%rd39];
	ld.global.f32 	%f2, [%rd37];
	add.f32 	%f3, %f2, %f1;
	st.global.f32 	[%rd39], %f3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB67_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB67_3;
	bra.uni 	$L__BB67_10;

$L__BB67_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB67_9;

$L__BB67_10:
	ret;

}
	// .globl	sa_u8_f64
.visible .entry sa_u8_f64(
	.param .u64 sa_u8_f64_param_0,
	.param .u64 sa_u8_f64_param_1,
	.param .u64 sa_u8_f64_param_2,
	.param .u64 sa_u8_f64_param_3,
	.param .u64 sa_u8_f64_param_4,
	.param .u64 sa_u8_f64_param_5,
	.param .u64 sa_u8_f64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_f64_param_0];
	ld.param.u64 	%rd19, [sa_u8_f64_param_1];
	ld.param.u64 	%rd20, [sa_u8_f64_param_2];
	ld.param.u64 	%rd24, [sa_u8_f64_param_3];
	ld.param.u64 	%rd21, [sa_u8_f64_param_4];
	ld.param.u64 	%rd22, [sa_u8_f64_param_5];
	ld.param.u64 	%rd23, [sa_u8_f64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB68_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB68_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB68_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB68_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB68_6;

$L__BB68_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB68_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd44, 0;

$L__BB68_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.f64 	%fd1, [%rd39];
	ld.global.f64 	%fd2, [%rd37];
	add.f64 	%fd3, %fd2, %fd1;
	st.global.f64 	[%rd39], %fd3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd44, %r20;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB68_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd41, %r19;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB68_3;
	bra.uni 	$L__BB68_10;

$L__BB68_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd40, %r19;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB68_9;

$L__BB68_10:
	ret;

}
	// .globl	sa_u8_u8
.visible .entry sa_u8_u8(
	.param .u64 sa_u8_u8_param_0,
	.param .u64 sa_u8_u8_param_1,
	.param .u64 sa_u8_u8_param_2,
	.param .u64 sa_u8_u8_param_3,
	.param .u64 sa_u8_u8_param_4,
	.param .u64 sa_u8_u8_param_5,
	.param .u64 sa_u8_u8_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b16 	%rs<4>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<43>;


	ld.param.u64 	%rd18, [sa_u8_u8_param_0];
	ld.param.u64 	%rd19, [sa_u8_u8_param_1];
	ld.param.u64 	%rd20, [sa_u8_u8_param_2];
	ld.param.u64 	%rd24, [sa_u8_u8_param_3];
	ld.param.u64 	%rd21, [sa_u8_u8_param_4];
	ld.param.u64 	%rd22, [sa_u8_u8_param_5];
	ld.param.u64 	%rd23, [sa_u8_u8_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd39, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd39;
	@%p1 bra 	$L__BB69_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB69_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB69_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB69_5;

	div.u64 	%rd40, %rd39, %rd23;
	mul.lo.s64 	%rd26, %rd40, %rd23;
	sub.s64 	%rd41, %rd39, %rd26;
	bra.uni 	$L__BB69_6;

$L__BB69_5:
	cvt.u32.u64 	%r14, %rd39;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd40, %r15;
	cvt.u64.u32 	%rd41, %r17;

$L__BB69_6:
	mul.lo.s64 	%rd13, %rd40, %rd21;
	mul.lo.s64 	%rd14, %rd40, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd42, 0;

$L__BB69_7:
	add.s64 	%rd28, %rd42, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd41;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd41;
	add.s64 	%rd36, %rd4, %rd30;
	add.s64 	%rd37, %rd3, %rd35;
	ld.global.u8 	%rs1, [%rd37];
	ld.global.u8 	%rs2, [%rd36];
	add.s16 	%rs3, %rs1, %rs2;
	st.global.u8 	[%rd37], %rs3;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd42, %r20;
	setp.lt.u64 	%p4, %rd42, %rd21;
	@%p4 bra 	$L__BB69_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd39, %r19;
	setp.gt.u64 	%p5, %rd2, %rd39;
	@%p5 bra 	$L__BB69_3;
	bra.uni 	$L__BB69_10;

$L__BB69_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd38, %r19;
	setp.gt.u64 	%p6, %rd2, %rd38;
	@%p6 bra 	$L__BB69_9;

$L__BB69_10:
	ret;

}
	// .globl	sa_u8_u32
.visible .entry sa_u8_u32(
	.param .u64 sa_u8_u32_param_0,
	.param .u64 sa_u8_u32_param_1,
	.param .u64 sa_u8_u32_param_2,
	.param .u64 sa_u8_u32_param_3,
	.param .u64 sa_u8_u32_param_4,
	.param .u64 sa_u8_u32_param_5,
	.param .u64 sa_u8_u32_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<25>;
	.reg .b64 	%rd<45>;


	ld.param.u64 	%rd18, [sa_u8_u32_param_0];
	ld.param.u64 	%rd19, [sa_u8_u32_param_1];
	ld.param.u64 	%rd20, [sa_u8_u32_param_2];
	ld.param.u64 	%rd24, [sa_u8_u32_param_3];
	ld.param.u64 	%rd21, [sa_u8_u32_param_4];
	ld.param.u64 	%rd22, [sa_u8_u32_param_5];
	ld.param.u64 	%rd23, [sa_u8_u32_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r22, %r10, %r1, %r11;
	cvt.u64.u32 	%rd41, %r22;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd41;
	@%p1 bra 	$L__BB70_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB70_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB70_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB70_5;

	div.u64 	%rd42, %rd41, %rd23;
	mul.lo.s64 	%rd26, %rd42, %rd23;
	sub.s64 	%rd43, %rd41, %rd26;
	bra.uni 	$L__BB70_6;

$L__BB70_5:
	cvt.u32.u64 	%r14, %rd41;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd42, %r15;
	cvt.u64.u32 	%rd43, %r17;

$L__BB70_6:
	mul.lo.s64 	%rd13, %rd42, %rd21;
	mul.lo.s64 	%rd14, %rd42, %rd22;
	mov.u32 	%r23, 0;
	mov.u64 	%rd44, 0;

$L__BB70_7:
	add.s64 	%rd28, %rd44, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd43;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd43;
	shl.b64 	%rd36, %rd30, 2;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 2;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u32 	%r19, [%rd39];
	ld.global.u32 	%r20, [%rd37];
	add.s32 	%r21, %r19, %r20;
	st.global.u32 	[%rd39], %r21;
	add.s32 	%r23, %r23, 1;
	cvt.u64.u32 	%rd44, %r23;
	setp.lt.u64 	%p4, %rd44, %rd21;
	@%p4 bra 	$L__BB70_7;

	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd41, %r22;
	setp.gt.u64 	%p5, %rd2, %rd41;
	@%p5 bra 	$L__BB70_3;
	bra.uni 	$L__BB70_10;

$L__BB70_9:
	add.s32 	%r22, %r22, %r3;
	cvt.u64.u32 	%rd40, %r22;
	setp.gt.u64 	%p6, %rd2, %rd40;
	@%p6 bra 	$L__BB70_9;

$L__BB70_10:
	ret;

}
	// .globl	sa_u8_i64
.visible .entry sa_u8_i64(
	.param .u64 sa_u8_i64_param_0,
	.param .u64 sa_u8_i64_param_1,
	.param .u64 sa_u8_i64_param_2,
	.param .u64 sa_u8_i64_param_3,
	.param .u64 sa_u8_i64_param_4,
	.param .u64 sa_u8_i64_param_5,
	.param .u64 sa_u8_i64_param_6
)
{
	.reg .pred 	%p<7>;
	.reg .b32 	%r<22>;
	.reg .b64 	%rd<48>;


	ld.param.u64 	%rd18, [sa_u8_i64_param_0];
	ld.param.u64 	%rd19, [sa_u8_i64_param_1];
	ld.param.u64 	%rd20, [sa_u8_i64_param_2];
	ld.param.u64 	%rd24, [sa_u8_i64_param_3];
	ld.param.u64 	%rd21, [sa_u8_i64_param_4];
	ld.param.u64 	%rd22, [sa_u8_i64_param_5];
	ld.param.u64 	%rd23, [sa_u8_i64_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r10, %ctaid.x;
	mov.u32 	%r11, %tid.x;
	mad.lo.s32 	%r19, %r10, %r1, %r11;
	cvt.u64.u32 	%rd44, %r19;
	mul.lo.s64 	%rd2, %rd23, %rd24;
	setp.le.u64 	%p1, %rd2, %rd44;
	@%p1 bra 	$L__BB71_10;

	setp.eq.s64 	%p2, %rd21, 0;
	mov.u32 	%r12, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r12;
	@%p2 bra 	$L__BB71_9;

	cvta.to.global.u64 	%rd3, %rd20;
	cvta.to.global.u64 	%rd4, %rd19;
	cvta.to.global.u64 	%rd5, %rd18;
	cvt.u32.u64 	%r13, %rd23;

$L__BB71_3:
	and.b64  	%rd25, %rd23, -4294967296;
	setp.eq.s64 	%p3, %rd25, 0;
	@%p3 bra 	$L__BB71_5;

	div.u64 	%rd45, %rd44, %rd23;
	mul.lo.s64 	%rd26, %rd45, %rd23;
	sub.s64 	%rd46, %rd44, %rd26;
	bra.uni 	$L__BB71_6;

$L__BB71_5:
	cvt.u32.u64 	%r14, %rd44;
	div.u32 	%r15, %r14, %r13;
	mul.lo.s32 	%r16, %r15, %r13;
	sub.s32 	%r17, %r14, %r16;
	cvt.u64.u32 	%rd45, %r15;
	cvt.u64.u32 	%rd46, %r17;

$L__BB71_6:
	mul.lo.s64 	%rd13, %rd45, %rd21;
	mul.lo.s64 	%rd14, %rd45, %rd22;
	mov.u32 	%r20, 0;
	mov.u64 	%rd47, 0;

$L__BB71_7:
	add.s64 	%rd28, %rd47, %rd13;
	mul.lo.s64 	%rd29, %rd28, %rd23;
	add.s64 	%rd30, %rd29, %rd46;
	add.s64 	%rd31, %rd5, %rd30;
	ld.global.u8 	%rd32, [%rd31];
	add.s64 	%rd33, %rd14, %rd32;
	mul.lo.s64 	%rd34, %rd33, %rd23;
	add.s64 	%rd35, %rd34, %rd46;
	shl.b64 	%rd36, %rd30, 3;
	add.s64 	%rd37, %rd4, %rd36;
	shl.b64 	%rd38, %rd35, 3;
	add.s64 	%rd39, %rd3, %rd38;
	ld.global.u64 	%rd40, [%rd39];
	ld.global.u64 	%rd41, [%rd37];
	add.s64 	%rd42, %rd40, %rd41;
	st.global.u64 	[%rd39], %rd42;
	add.s32 	%r20, %r20, 1;
	cvt.u64.u32 	%rd47, %r20;
	setp.lt.u64 	%p4, %rd47, %rd21;
	@%p4 bra 	$L__BB71_7;

	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd44, %r19;
	setp.gt.u64 	%p5, %rd2, %rd44;
	@%p5 bra 	$L__BB71_3;
	bra.uni 	$L__BB71_10;

$L__BB71_9:
	add.s32 	%r19, %r19, %r3;
	cvt.u64.u32 	%rd43, %r19;
	setp.gt.u64 	%p6, %rd2, %rd43;
	@%p6 bra 	$L__BB71_9;

$L__BB71_10:
	ret;

}

